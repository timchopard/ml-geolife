{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17159bbd",
   "metadata": {
    "papermill": {
     "duration": 0.006704,
     "end_time": "2024-05-05T14:42:28.165291",
     "exception": false,
     "start_time": "2024-05-05T14:42:28.158587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# This is an INFERENCE using the model combine the method of MLP, CNN and Transformer\n",
    "\n",
    "Thanks PICEKL for his baseline, which help me a lot.\n",
    "\n",
    "The main idea of this method is to obtain multiple features from multiple dimensions. We simply divide it into four types: **image information** with spatial characteristics, **meta information** that is independent of each other, **climate information** and **satellite information** with time characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1703a0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T21:25:07.29831Z",
     "start_time": "2024-04-30T21:25:05.354584Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-05T14:42:41.363659Z",
     "iopub.status.busy": "2024-05-05T14:42:41.363369Z",
     "iopub.status.idle": "2024-05-05T14:42:49.299669Z",
     "shell.execute_reply": "2024-05-05T14:42:49.298878Z"
    },
    "papermill": {
     "duration": 7.946835,
     "end_time": "2024-05-05T14:42:49.302146",
     "exception": false,
     "start_time": "2024-05-05T14:42:41.355311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/startung/miniconda3/envs/pt/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/startung/miniconda3/envs/pt/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange, repeat\n",
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1faf2acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir = Path(\"output\") / time.strftime('%Y-%m-%d_%H%M', time.localtime())\n",
    "new_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c275e9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T14:42:49.317022Z",
     "iopub.status.busy": "2024-05-05T14:42:49.316581Z",
     "iopub.status.idle": "2024-05-05T14:42:49.320755Z",
     "shell.execute_reply": "2024-05-05T14:42:49.319956Z"
    },
    "papermill": {
     "duration": 0.013539,
     "end_time": "2024-05-05T14:42:49.322641",
     "exception": false,
     "start_time": "2024-05-05T14:42:49.309102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_classes = 11255\n",
    "num_epochs = 10\n",
    "seed = 113"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f91a65",
   "metadata": {
    "papermill": {
     "duration": 0.006362,
     "end_time": "2024-05-05T14:42:49.335533",
     "exception": false,
     "start_time": "2024-05-05T14:42:49.329171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When reading data, different **fusion** and **normalization** will be performed for different types of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccd14039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f58e2be8250>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af853980",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T21:25:32.627928Z",
     "start_time": "2024-04-30T21:25:32.612131Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-05T14:42:49.350022Z",
     "iopub.status.busy": "2024-05-05T14:42:49.349757Z",
     "iopub.status.idle": "2024-05-05T14:42:49.375102Z",
     "shell.execute_reply": "2024-05-05T14:42:49.374208Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.035054,
     "end_time": "2024-05-05T14:42:49.377072",
     "exception": false,
     "start_time": "2024-05-05T14:42:49.342018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, metadata, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "        self.metadata = metadata\n",
    "\n",
    "        self.metadata = self.metadata.drop_duplicates(subset=\"surveyId\").reset_index(drop=True)\n",
    "        self.metadata.fillna(0,inplace=True)\n",
    "        self.metadata.replace({float('-inf'): 0}, inplace=True)\n",
    "        self.metadata_data = self.Norm(self.metadata.iloc[:,:5])\n",
    "\n",
    "        self.merge_key = 'surveyId'\n",
    "        self.climate_average = pd.read_csv(\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/Climate/Average 1981-2010/GLC24-PA-test-bioclimatic.csv\")\n",
    "        self.climate_monthly = pd.read_csv(\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/Climate/Monthly/GLC24-PA-test-bioclimatic_monthly.csv\")\n",
    "        self.climate = pd.merge(self.climate_average, self.climate_monthly, on=self.merge_key)\n",
    "        self.climate.fillna(self.climate.mean(),inplace=True)\n",
    "        self.climate_data = self.Norm_all(self.climate)\n",
    "\n",
    "        self.landsat_b = pd.read_csv(\"data/geolifeclef-2024/PA-test-landsat_time_series/GLC24-PA-test-landsat_time_series-blue.csv\")\n",
    "        self.landsat_b.fillna(self.landsat_b.mean(),inplace=True)\n",
    "        self.landsat_g = pd.read_csv(\"data/geolifeclef-2024/PA-test-landsat_time_series/GLC24-PA-test-landsat_time_series-green.csv\")\n",
    "        self.landsat_g.fillna(self.landsat_g.mean(),inplace=True)\n",
    "        self.landsat_r = pd.read_csv(\"data/geolifeclef-2024/PA-test-landsat_time_series/GLC24-PA-test-landsat_time_series-red.csv\")\n",
    "        self.landsat_r.fillna(self.landsat_r.mean(),inplace=True)\n",
    "        self.landsat_n = pd.read_csv(\"data/geolifeclef-2024/PA-test-landsat_time_series/GLC24-PA-test-landsat_time_series-nir.csv\")\n",
    "        self.landsat_n.fillna(self.landsat_n.mean(),inplace=True)\n",
    "        self.landsat_s1 = pd.read_csv(\"data/geolifeclef-2024/PA-test-landsat_time_series/GLC24-PA-test-landsat_time_series-swir1.csv\")\n",
    "        self.landsat_s1.fillna(self.landsat_s1.mean(),inplace=True)\n",
    "        self.landsat_s2 = pd.read_csv(\"data/geolifeclef-2024/PA-test-landsat_time_series/GLC24-PA-test-landsat_time_series-swir2.csv\")\n",
    "        self.landsat_s2.fillna(self.landsat_s2.mean(),inplace=True)\n",
    "        self.landsat_data = torch.cat([self.Norm_all(self.landsat_b),self.Norm_all(self.landsat_g),self.Norm_all(self.landsat_r),self.Norm_all(self.landsat_n),self.Norm_all(self.landsat_s1),self.Norm_all(self.landsat_s2)],axis=1)\n",
    "\n",
    "        self.elevation = pd.read_csv(\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/Elevation/GLC24-PA-test-elevation.csv\")\n",
    "        self.elevation[self.elevation<0]=0\n",
    "        self.elevation.fillna(self.elevation.mean(),inplace=True)\n",
    "        self.elevation_data = self.Norm(self.elevation)\n",
    "\n",
    "        self.human_footprint = pd.read_csv(\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/Human Footprint/GLC24-PA-test-human_footprint.csv\")\n",
    "        self.human_footprint[self.human_footprint<0]=0\n",
    "        self.human_footprint.fillna(self.human_footprint.mean(),inplace=True)\n",
    "        self.human_footprint_data = self.Norm(self.human_footprint)\n",
    "\n",
    "        self.landcover = pd.read_csv(\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/LandCover/GLC24-PA-test-landcover.csv\")\n",
    "        self.landcover[self.landcover<0]=0\n",
    "        self.landcover.fillna(self.landcover.mean(),inplace=True)\n",
    "        self.landcover_data = self.Norm(self.landcover)\n",
    "\n",
    "        self.soilgrids = pd.read_csv(\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/SoilGrids/GLC24-PA-test-soilgrids.csv\")\n",
    "        self.soilgrids[self.soilgrids<0]=0\n",
    "        self.soilgrids.fillna(self.soilgrids.mean(),inplace=True)\n",
    "        self.soilgrids_data = self.Norm(self.soilgrids)\n",
    "\n",
    "        self.metadata_data = torch.cat((self.metadata_data, self.elevation_data, self.human_footprint_data, self.landcover_data, self.soilgrids_data), dim=1)\n",
    "\n",
    "    def Norm(self,df):\n",
    "        output=torch.from_numpy(df.iloc[:,1:].values).float()\n",
    "        return (output-output.mean(dim=0))/output.std(dim=0)\n",
    "\n",
    "    def Norm_all(self,df):\n",
    "        output=torch.from_numpy(df.iloc[:,1:].values).float()\n",
    "        return (output-output.mean())/output.std()\n",
    "\n",
    "    def patch_rgb_path(self,survey_id):\n",
    "        path = \"data/geolifeclef-2024/PA_Test_SatellitePatches_RGB/pa_test_patches_rgb\"\n",
    "        for d in (str(survey_id)[-2:], str(survey_id)[-4:-2]):\n",
    "            path = os.path.join(path, d)\n",
    "        path = os.path.join(path, f\"{survey_id}.jpeg\")\n",
    "        return path\n",
    "\n",
    "    def patch_nir_path(self,survey_id):\n",
    "        path = \"data/geolifeclef-2024/PA_Test_SatellitePatches_NIR/pa_test_patches_nir\"\n",
    "        for d in (str(survey_id)[-2:], str(survey_id)[-4:-2]):\n",
    "            path = os.path.join(path, d)\n",
    "        path = os.path.join(path, f\"{survey_id}.jpeg\")\n",
    "        return path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        survey_id = self.metadata.surveyId[idx]\n",
    "\n",
    "        image_path = self.patch_rgb_path(survey_id)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        image = image.unsqueeze(0)\n",
    "        image_nir_path = self.patch_nir_path(survey_id)\n",
    "        nir_image = Image.open(image_nir_path).convert(\"L\")\n",
    "        nir_image = self.transform(nir_image)\n",
    "        nir_image = nir_image.unsqueeze(0)\n",
    "        image_data = torch.cat([image,nir_image],dim=1)\n",
    "        image_data = torch.squeeze(image_data)\n",
    "        sample=[self.metadata_data[idx,:],image_data,self.landsat_data[idx,:],self.climate_data[idx,:]]\n",
    "        return sample, survey_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39b64182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T21:25:34.532017Z",
     "start_time": "2024-04-30T21:25:32.615562Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-05T14:42:49.391704Z",
     "iopub.status.busy": "2024-05-05T14:42:49.391421Z",
     "iopub.status.idle": "2024-05-05T14:42:51.305244Z",
     "shell.execute_reply": "2024-05-05T14:42:51.304427Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.923732,
     "end_time": "2024-05-05T14:42:51.307566",
     "exception": false,
     "start_time": "2024-05-05T14:42:49.383834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset and DataLoader\n",
    "train_batch_size = 64\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load testing data\n",
    "test_metadata_path = \"data/geolifeclef-2024/GLC24_PA_metadata_test.csv\"\n",
    "test_metadata = pd.read_csv(test_metadata_path)\n",
    "test_dataset = TestDataset(test_metadata, subset=\"test\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad70c7af",
   "metadata": {
    "papermill": {
     "duration": 0.006496,
     "end_time": "2024-05-05T14:42:51.321299",
     "exception": false,
     "start_time": "2024-05-05T14:42:51.314803",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is an MLP used to extract features from generally independent information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7143060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T14:42:51.335647Z",
     "iopub.status.busy": "2024-05-05T14:42:51.335345Z",
     "iopub.status.idle": "2024-05-05T14:42:51.341096Z",
     "shell.execute_reply": "2024-05-05T14:42:51.340279Z"
    },
    "papermill": {
     "duration": 0.015091,
     "end_time": "2024-05-05T14:42:51.342937",
     "exception": false,
     "start_time": "2024-05-05T14:42:51.327846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(dim, out_dim*5)\n",
    "        self.fc2 = nn.Linear(out_dim*5, out_dim)\n",
    "        self.norm = nn.LayerNorm(out_dim*5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = self.norm(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18c14da",
   "metadata": {
    "papermill": {
     "duration": 0.006331,
     "end_time": "2024-05-05T14:42:51.355818",
     "exception": false,
     "start_time": "2024-05-05T14:42:51.349487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following is the part of ViT, which can also be considered as the Encoder part of **Transformer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c372000",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T14:42:51.369938Z",
     "iopub.status.busy": "2024-05-05T14:42:51.369682Z",
     "iopub.status.idle": "2024-05-05T14:42:51.377708Z",
     "shell.execute_reply": "2024-05-05T14:42:51.376886Z"
    },
    "papermill": {
     "duration": 0.017177,
     "end_time": "2024-05-05T14:42:51.379537",
     "exception": false,
     "start_time": "2024-05-05T14:42:51.362360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Multihead_self_attention(nn.Module):\n",
    "    def __init__(self, heads, head_dim, dim):\n",
    "        super().__init__()\n",
    "        self.head_dim = head_dim\n",
    "        self.heads = heads\n",
    "        self.inner_dim = self.heads*self.head_dim\n",
    "        self.scale = self.head_dim**-0.5\n",
    "        self.to_qkv = nn.Linear(dim, self.inner_dim*3)\n",
    "        self.to_output = nn.Linear(self.inner_dim, dim)\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        Q, K, V = map(lambda t: rearrange(t, 'b l (h dim) -> b h l dim', dim=self.head_dim), qkv)\n",
    "        K_T = K.transpose(-1, -2)\n",
    "        att_score = Q@K_T*self.scale\n",
    "        att = self.softmax(att_score)\n",
    "        out = att@V   # (B,H,L,dim)\n",
    "        out = rearrange(out, 'b h l dim -> b l (h dim)')\n",
    "        output = self.to_output(out)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3b7da87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T14:42:51.394418Z",
     "iopub.status.busy": "2024-05-05T14:42:51.394157Z",
     "iopub.status.idle": "2024-05-05T14:42:51.399714Z",
     "shell.execute_reply": "2024-05-05T14:42:51.398927Z"
    },
    "papermill": {
     "duration": 0.014669,
     "end_time": "2024-05-05T14:42:51.401491",
     "exception": false,
     "start_time": "2024-05-05T14:42:51.386822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, mlp_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(dim, mlp_dim)\n",
    "        self.fc2 = nn.Linear(mlp_dim, dim)\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        x = F.gelu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38ffea8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T14:42:51.415374Z",
     "iopub.status.busy": "2024-05-05T14:42:51.415124Z",
     "iopub.status.idle": "2024-05-05T14:42:51.420412Z",
     "shell.execute_reply": "2024-05-05T14:42:51.419638Z"
    },
    "papermill": {
     "duration": 0.014302,
     "end_time": "2024-05-05T14:42:51.422268",
     "exception": false,
     "start_time": "2024-05-05T14:42:51.407966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transformer_block(nn.Module):\n",
    "    def __init__(self, dim, heads, head_dim, mlp_dim):\n",
    "        super().__init__()\n",
    "        self.MHA = Multihead_self_attention(heads=heads, head_dim=head_dim, dim=dim)\n",
    "        self.FeedForward = FeedForward(dim=dim, mlp_dim=mlp_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.MHA(x)+x\n",
    "        x = self.FeedForward(x)+x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "455d578b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T14:42:51.436184Z",
     "iopub.status.busy": "2024-05-05T14:42:51.435904Z",
     "iopub.status.idle": "2024-05-05T14:42:51.441971Z",
     "shell.execute_reply": "2024-05-05T14:42:51.441163Z"
    },
    "papermill": {
     "duration": 0.015236,
     "end_time": "2024-05-05T14:42:51.443905",
     "exception": false,
     "start_time": "2024-05-05T14:42:51.428669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ViT(nn.Module):\n",
    "    def __init__(self, dim, heads, head_dim, mlp_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.transformer = Transformer_block(dim=dim, heads=heads, head_dim=head_dim, mlp_dim=mlp_dim)\n",
    "\n",
    "        self.MLP_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, num_class)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer(x)\n",
    "        CLS_token = x[:, 0, :]\n",
    "        out = self.MLP_head(CLS_token)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7688f26e",
   "metadata": {
    "papermill": {
     "duration": 0.006234,
     "end_time": "2024-05-05T14:42:51.456632",
     "exception": false,
     "start_time": "2024-05-05T14:42:51.450398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following is **CNN**, used to extract feature information from images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70f497c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T14:42:51.470881Z",
     "iopub.status.busy": "2024-05-05T14:42:51.470190Z",
     "iopub.status.idle": "2024-05-05T14:42:51.476395Z",
     "shell.execute_reply": "2024-05-05T14:42:51.475611Z"
    },
    "papermill": {
     "duration": 0.015063,
     "end_time": "2024-05-05T14:42:51.478141",
     "exception": false,
     "start_time": "2024-05-05T14:42:51.463078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet18, self).__init__()\n",
    "\n",
    "        self.resnet18 = models.resnet18(weights=None)\n",
    "        self.resnet18.conv1 = nn.Conv2d(4, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.resnet18.maxpool = nn.Identity()\n",
    "        self.ln = nn.LayerNorm(1000)\n",
    "        self.fc1 = nn.Linear(1000, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet18(x)\n",
    "        x = self.ln(x)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b334f1d",
   "metadata": {
    "papermill": {
     "duration": 0.006256,
     "end_time": "2024-05-05T14:42:51.490923",
     "exception": false,
     "start_time": "2024-05-05T14:42:51.484667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is the **final multi-modal model**. Unlike ViT, its input is features extracted from each dimension. \n",
    "\n",
    "For features with time information, I added additional position information. \n",
    "\n",
    "At the same time, I also added a feature that is a fusion of the first four features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f8dde92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T14:42:51.505245Z",
     "iopub.status.busy": "2024-05-05T14:42:51.504543Z",
     "iopub.status.idle": "2024-05-05T14:42:51.515887Z",
     "shell.execute_reply": "2024-05-05T14:42:51.515235Z"
    },
    "papermill": {
     "duration": 0.020283,
     "end_time": "2024-05-05T14:42:51.517661",
     "exception": false,
     "start_time": "2024-05-05T14:42:51.497378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiModal(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultiModal, self).__init__()\n",
    "        self.cls = nn.Parameter(torch.randn(1, 1, 200))\n",
    "        self.meta = Embedding(31,200)\n",
    "        self.resnet18 = ResNet18(200)\n",
    "        self.landsat = Embedding(504,200)\n",
    "        self.position_landsat = nn.Parameter(torch.randn(1, 504))\n",
    "        self.climate = Embedding(931,200)\n",
    "        self.position_climate = nn.Parameter(torch.randn(1, 931))\n",
    "        self.emb = Embedding(800,200)\n",
    "        self.position_combine = nn.Parameter(torch.randn(1, 800))\n",
    "        self.vit = ViT(200, 2, 200, 400, num_classes)\n",
    "        self.position = nn.Parameter(torch.randn(1, 6, 200))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch = x[0].size(0)\n",
    "        CLS = repeat(self.cls, '1 1 d -> b 1 d', b=batch).to(device)\n",
    "        META = self.meta(x[0])\n",
    "        IMG = self.resnet18(x[1])\n",
    "        LANDSAT = self.landsat(x[2]+self.position_landsat)\n",
    "        CLIMATE = self.climate(x[3]+self.position_climate)\n",
    "        combine = torch.cat((META, IMG, LANDSAT, CLIMATE), dim=1)\n",
    "        COMBINE = self.emb(combine+self.position_combine)\n",
    "        token = torch.concat((CLS, META.unsqueeze(1)), dim=1)\n",
    "        token = torch.concat((token, IMG.unsqueeze(1)), dim=1)\n",
    "        token = torch.concat((token, LANDSAT.unsqueeze(1)), dim=1)\n",
    "        token = torch.concat((token, CLIMATE.unsqueeze(1)), dim=1)\n",
    "        token = torch.concat((token, COMBINE.unsqueeze(1)), dim=1)\n",
    "        out = self.vit(token+self.position)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8e1f40e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T21:25:31.611823Z",
     "start_time": "2024-04-30T21:25:31.607373Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-05T14:42:51.531532Z",
     "iopub.status.busy": "2024-05-05T14:42:51.531262Z",
     "iopub.status.idle": "2024-05-05T14:42:52.798635Z",
     "shell.execute_reply": "2024-05-05T14:42:52.797682Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.276491,
     "end_time": "2024-05-05T14:42:52.800566",
     "exception": false,
     "start_time": "2024-05-05T14:42:51.524075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE = CUDA\n"
     ]
    }
   ],
   "source": [
    "# Check if cuda is available\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"DEVICE = CUDA\")\n",
    "\n",
    "model = MultiModal(num_classes).to(device)\n",
    "model.load_state_dict(torch.load(\"output/2024-06-04_1943-e10-0.29103/multimodal-epoch-0.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fa615b",
   "metadata": {},
   "source": [
    "## Produce Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ad6677f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-30T21:25:34.536634Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-05T14:42:52.815910Z",
     "iopub.status.busy": "2024-05-05T14:42:52.815177Z",
     "iopub.status.idle": "2024-05-05T14:44:06.291126Z",
     "shell.execute_reply": "2024-05-05T14:44:06.288992Z"
    },
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 73.485486,
     "end_time": "2024-05-05T14:44:06.293057",
     "exception": false,
     "start_time": "2024-05-05T14:42:52.807571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4716/4716 [00:25<00:00, 184.81it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    surveys = []\n",
    "    top_indices = []\n",
    "    for data, surveyID in tqdm(test_loader, total=len(test_loader)):\n",
    "\n",
    "        data = [tensor.to(device) for tensor in data]\n",
    "\n",
    "        outputs = model(data)\n",
    "        predictions = torch.sigmoid(outputs).cpu().numpy()\n",
    "        predictions = np.squeeze(predictions)\n",
    "        prediction = np.argwhere(predictions>=0.25).flatten()\n",
    "        top_indices.append(prediction)\n",
    "        surveys.extend(surveyID.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6632f95d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T14:44:06.404548Z",
     "iopub.status.busy": "2024-05-05T14:44:06.404201Z",
     "iopub.status.idle": "2024-05-05T14:44:06.506275Z",
     "shell.execute_reply": "2024-05-05T14:44:06.505581Z"
    },
    "papermill": {
     "duration": 0.159619,
     "end_time": "2024-05-05T14:44:06.508072",
     "exception": false,
     "start_time": "2024-05-05T14:44:06.348453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_concatenated = [' '.join(map(str, row)) for row in top_indices]\n",
    "\n",
    "pd.DataFrame(\n",
    "    {'surveyId': surveys,\n",
    "     'predictions': data_concatenated,\n",
    "    }).to_csv(new_dir / \"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f553810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of predictions: 76664 with average of 16.256149279050042 predictions per survey ID.\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for row in top_indices:\n",
    "    total += row.shape[0]\n",
    "\n",
    "print(f\"Total number of predictions: {total} with average of {total/len(top_indices)} predictions per survey ID.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8171035,
     "sourceId": 64733,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 36765,
     "sourceId": 43782,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 102.728954,
   "end_time": "2024-05-05T14:44:08.185017",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-05T14:42:25.456063",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
