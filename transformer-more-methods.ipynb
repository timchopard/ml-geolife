{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"ExecuteTime":{"end_time":"2024-04-30T21:25:07.29831Z","start_time":"2024-04-30T21:25:05.354584Z"},"execution":{"iopub.execute_input":"2024-05-14T10:49:00.151239Z","iopub.status.busy":"2024-05-14T10:49:00.150932Z","iopub.status.idle":"2024-05-14T10:49:06.583701Z","shell.execute_reply":"2024-05-14T10:49:06.582866Z","shell.execute_reply.started":"2024-05-14T10:49:00.151203Z"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/startung/miniconda3/envs/pt/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n","  warn(\n"]}],"source":["import os\n","import torch\n","import tqdm\n","import numpy as np\n","import pandas as pd\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from sklearn.metrics import precision_recall_fscore_support\n","from PIL import Image\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from einops.layers.torch import Rearrange\n","from einops import rearrange, repeat"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T10:49:06.585291Z","iopub.status.busy":"2024-05-14T10:49:06.584735Z","iopub.status.idle":"2024-05-14T10:49:06.589934Z","shell.execute_reply":"2024-05-14T10:49:06.589042Z","shell.execute_reply.started":"2024-05-14T10:49:06.585265Z"},"trusted":true},"outputs":[],"source":["# Hyperparameters\n","learning_rate = 0.00025\n","num_epochs = 1\n","positive_weigh_factor = 1.0\n","INITIAL_SEED = 113\n","test_batch_size = 64\n","num_classes = 11255 # max 11255"]},{"cell_type":"markdown","metadata":{},"source":["When reading data, different **fusion** and **normalization** will be performed for different types of data."]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T10:49:06.592418Z","iopub.status.busy":"2024-05-14T10:49:06.592097Z","iopub.status.idle":"2024-05-14T10:49:06.618840Z","shell.execute_reply":"2024-05-14T10:49:06.617985Z","shell.execute_reply.started":"2024-05-14T10:49:06.592395Z"},"trusted":true},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, metadata, subset, transform=None):\n","        self.subset = subset\n","        self.transform = transform\n","        self.metadata = metadata\n","        self.merge_key = 'surveyId'\n","\n","        self.metadata_data = self.Norm(self.process_metadata())\n","        self.climate_data = self.Norm_all(self.process_climate())\n","        self.landsat_data = self.process_landsat()\n","        self.elevation_data = self.Norm(self.process_elevation())\n","        self.human_footprint_data = self.Norm(self.process_human_footprint())\n","        self.landcover_data = self.Norm(self.process_landcover())\n","        self.soilgrids_data = self.Norm(self.process_soilgrids())\n","\n","        self.metadata_data = torch.cat((\n","            self.metadata_data,\n","            self.elevation_data,\n","            self.human_footprint_data,\n","            self.landcover_data,\n","            self.soilgrids_data\n","        ), dim=1)\n","\n","    def process_climate(self):\n","        climate_average = pd.read_csv(f\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/Climate/Average 1981-2010/GLC24-PA-{self.subset}-bioclimatic.csv\")\n","        climate_monthly = pd.read_csv(f\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/Climate/Monthly/GLC24-PA-{self.subset}-bioclimatic_monthly.csv\")\n","        climate = pd.merge(climate_average, climate_monthly, on=self.merge_key)\n","        climate = climate.fillna(climate.mean())\n","        return climate\n","\n","    def process_landsat(self):\n","        landsat_b = pd.read_csv(f\"data/geolifeclef-2024/PA-{self.subset}-landsat_time_series/GLC24-PA-{self.subset}-landsat_time_series-blue.csv\")\n","        landsat_b = landsat_b.fillna(landsat_b.mean())\n","        landsat_g = pd.read_csv(f\"data/geolifeclef-2024/PA-{self.subset}-landsat_time_series/GLC24-PA-{self.subset}-landsat_time_series-green.csv\")\n","        landsat_g = landsat_g.fillna(landsat_g.mean())\n","        landsat_r = pd.read_csv(f\"data/geolifeclef-2024/PA-{self.subset}-landsat_time_series/GLC24-PA-{self.subset}-landsat_time_series-red.csv\")\n","        landsat_r = landsat_r.fillna(landsat_r.mean())\n","        landsat_n = pd.read_csv(f\"data/geolifeclef-2024/PA-{self.subset}-landsat_time_series/GLC24-PA-{self.subset}-landsat_time_series-nir.csv\")\n","        landsat_n = landsat_n.fillna(landsat_n.mean())\n","        landsat_s1 = pd.read_csv(f\"data/geolifeclef-2024/PA-{self.subset}-landsat_time_series/GLC24-PA-{self.subset}-landsat_time_series-swir1.csv\")\n","        landsat_s1 = landsat_s1.fillna(landsat_s1.mean())\n","        landsat_s2 = pd.read_csv(f\"data/geolifeclef-2024/PA-{self.subset}-landsat_time_series/GLC24-PA-{self.subset}-landsat_time_series-swir2.csv\")\n","        landsat_s2 = landsat_s2.fillna(landsat_s2.mean())\n","        return torch.cat([self.Norm_all(landsat_b),self.Norm_all(landsat_g),self.Norm_all(landsat_r),self.Norm_all(landsat_n),self.Norm_all(landsat_s1),self.Norm_all(landsat_s2)],axis=1)\n","\n","    def process_elevation(self):\n","        elevation = pd.read_csv(f\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/Elevation/GLC24-PA-{self.subset}-elevation.csv\")\n","        elevation[elevation<0]=0\n","        elevation = elevation.fillna(elevation.mean())\n","        return elevation\n","\n","    def process_human_footprint(self):\n","        human_footprint = pd.read_csv(f\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/Human Footprint/GLC24-PA-{self.subset}-human_footprint.csv\")\n","        human_footprint[human_footprint<0]=0\n","        human_footprint = human_footprint.fillna(human_footprint.mean())\n","        return human_footprint\n","\n","    def process_landcover(self):\n","        landcover = pd.read_csv(f\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/LandCover/GLC24-PA-{self.subset}-landcover.csv\")\n","        landcover[landcover<0]=0\n","        landcover = landcover.fillna(landcover.mean())\n","        return landcover\n","\n","    def process_soilgrids(self):\n","        soilgrids = pd.read_csv(f\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/SoilGrids/GLC24-PA-{self.subset}-soilgrids.csv\")\n","        soilgrids[soilgrids<0]=0\n","        soilgrids = soilgrids.fillna(soilgrids.mean())\n","        return soilgrids\n","\n","    def process_metadata(self):\n","        metadata = self.metadata.drop_duplicates(subset=\"surveyId\").reset_index(drop=True)\n","        metadata.fillna(0,inplace=True)\n","        metadata.replace({float('-inf'): 0}, inplace=True)\n","        return metadata.iloc[:,:5]\n","\n","    def Norm(self,df):\n","        output=torch.from_numpy(df.iloc[:,1:].values).float()\n","        return (output-output.mean(dim=0))/output.std(dim=0)\n","\n","    def Norm_all(self,df):\n","        output=torch.from_numpy(df.iloc[:,1:].values).float()\n","        return (output-output.mean())/output.std()\n","\n","    def patch_rgb_path(self,survey_id):\n","        path = f\"data/geolifeclef-2024/PA_{self.subset.title()}_SatellitePatches_RGB/pa_{self.subset}_patches_rgb\"\n","        for d in (str(survey_id)[-2:], str(survey_id)[-4:-2]):\n","            path = os.path.join(path, d)\n","        path = os.path.join(path, f\"{survey_id}.jpeg\")\n","        return path\n","\n","    def patch_nir_path(self,survey_id):\n","        path = f\"data/geolifeclef-2024/PA_{self.subset.title()}_SatellitePatches_NIR/pa_{self.subset}_patches_nir\"\n","        for d in (str(survey_id)[-2:], str(survey_id)[-4:-2]):\n","            path = os.path.join(path, d)\n","        path = os.path.join(path, f\"{survey_id}.jpeg\")\n","        return path\n","\n","    def __len__(self):\n","        return len(self.metadata)\n","\n","    def __getitem__(self, idx):\n","\n","        survey_id = self.metadata.surveyId[idx]\n","\n","        image_path = self.patch_rgb_path(survey_id)\n","        image = Image.open(image_path).convert(\"RGB\")\n","        image = self.transform(image)\n","        image = image.unsqueeze(0)\n","        image_nir_path = self.patch_nir_path(survey_id)\n","        nir_image = Image.open(image_nir_path).convert(\"L\")\n","        nir_image = self.transform(nir_image)\n","        nir_image = nir_image.unsqueeze(0)\n","        image_data = torch.cat([image,nir_image],dim=1)\n","        image_data = torch.squeeze(image_data)\n","        sample=[self.metadata_data[idx,:],image_data,self.landsat_data[idx,:],self.climate_data[idx,:]]\n","        return sample, survey_id"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["class TestDataset(CustomDataset):\n","    def __init__(self, metadata, transform=None):\n","        super().__init__(metadata, subset=\"test\", transform=transform)\n","\n","    # def __getitem__(self, idx):\n","    #     sample, survey_id = super().__getitem__(idx)\n","    #     return sample, survey_id"]},{"cell_type":"code","execution_count":5,"metadata":{"ExecuteTime":{"end_time":"2024-04-30T21:25:32.627928Z","start_time":"2024-04-30T21:25:32.612131Z"},"collapsed":false,"execution":{"iopub.execute_input":"2024-05-14T10:49:06.620239Z","iopub.status.busy":"2024-05-14T10:49:06.619985Z","iopub.status.idle":"2024-05-14T10:49:06.647821Z","shell.execute_reply":"2024-05-14T10:49:06.646953Z","shell.execute_reply.started":"2024-05-14T10:49:06.620218Z"},"jupyter":{"outputs_hidden":false},"tags":[],"trusted":true},"outputs":[],"source":["class TrainDataset(CustomDataset):\n","    def __init__(self, metadata, transform=None):\n","        super().__init__(metadata, subset=\"train\", transform=transform)\n","\n","        self.metadata['speciesId'] = self.metadata['speciesId'].astype(int)\n","        self.label_dict = self.metadata.groupby('surveyId')['speciesId'].apply(list).to_dict()\n","\n","    # def Norm(self,df):\n","    #     output=torch.from_numpy(df.iloc[:,1:].values).float()\n","    #     return (output-output.mean(dim=0))/output.std(dim=0)\n","\n","    # def Norm_all(self,df):\n","    #     output=torch.from_numpy(df.iloc[:,1:].values).float()\n","    #     return (output-output.mean())/output.std()\n","\n","    # def patch_rgb_path(self,survey_id):\n","    #     path = \"data/geolifeclef-2024/PA_Train_SatellitePatches_RGB/pa_train_patches_rgb\"\n","    #     for d in (str(survey_id)[-2:], str(survey_id)[-4:-2]):\n","    #         path = os.path.join(path, d)\n","    #     path = os.path.join(path, f\"{survey_id}.jpeg\")\n","    #     return path\n","\n","    # def patch_nir_path(self,survey_id):\n","    #     path = \"data/geolifeclef-2024/PA_Train_SatellitePatches_NIR/pa_train_patches_nir\"\n","    #     for d in (str(survey_id)[-2:], str(survey_id)[-4:-2]):\n","    #         path = os.path.join(path, d)\n","    #     path = os.path.join(path, f\"{survey_id}.jpeg\")\n","    #     return path\n","\n","    # def __len__(self):\n","    #     return len(self.metadata)\n","\n","    def __getitem__(self, idx):\n","\n","        survey_id = self.metadata.surveyId[idx]\n","        species_ids = self.label_dict.get(survey_id, [])  # Get list of species IDs for the survey ID\n","        label = torch.zeros(num_classes)  # Initialize label tensor\n","        for species_id in species_ids:\n","            label_id = species_id\n","            label[label_id] = 1  # Set the corresponding class index to 1 for each species\n","\n","        image_path = self.patch_rgb_path(survey_id)\n","        image = Image.open(image_path).convert(\"RGB\")\n","        image = self.transform(image)\n","        image = image.unsqueeze(0)\n","        image_nir_path = self.patch_nir_path(survey_id)\n","        nir_image = Image.open(image_nir_path).convert(\"L\")\n","        nir_image = self.transform(nir_image)\n","        nir_image = nir_image.unsqueeze(0)\n","        image_data = torch.cat([image,nir_image],dim=1)\n","        image_data = torch.squeeze(image_data)\n","        sample=[self.metadata_data[idx,:],image_data,self.landsat_data[idx,:],self.climate_data[idx,:]]\n","        return sample, survey_id, label"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T10:49:06.649209Z","iopub.status.busy":"2024-05-14T10:49:06.648896Z","iopub.status.idle":"2024-05-14T10:49:37.550931Z","shell.execute_reply":"2024-05-14T10:49:37.550137Z","shell.execute_reply.started":"2024-05-14T10:49:06.649180Z"},"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'data/geolifeclef-2024/PA-Train-landsat_time_series/GLC24-PA-train-landsat_time_series-blue.csv'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m train_metadata_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/geolifeclef-2024/GLC24_PA_metadata_train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m train_metadata \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(train_metadata_path)\n\u001b[0;32m---> 11\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m TrainDataset(train_metadata, transform\u001b[38;5;241m=\u001b[39mtrain_transform)\n\u001b[1;32m     12\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mtrain_batch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","Cell \u001b[0;32mIn[5], line 3\u001b[0m, in \u001b[0;36mTrainDataset.__init__\u001b[0;34m(self, metadata, transform)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, metadata, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(metadata, subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeciesId\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeciesId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurveyId\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeciesId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mlist\u001b[39m)\u001b[38;5;241m.\u001b[39mto_dict()\n","Cell \u001b[0;32mIn[3], line 10\u001b[0m, in \u001b[0;36mCustomDataset.__init__\u001b[0;34m(self, metadata, subset, transform)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_metadata())\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclimate_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNorm_all(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_climate())\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlandsat_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_landsat()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melevation_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_elevation())\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhuman_footprint_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_human_footprint())\n","Cell \u001b[0;32mIn[3], line 32\u001b[0m, in \u001b[0;36mCustomDataset.process_landsat\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_landsat\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 32\u001b[0m     landsat_b \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/geolifeclef-2024/PA-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset\u001b[38;5;241m.\u001b[39mtitle()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-landsat_time_series/GLC24-PA-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-landsat_time_series-blue.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m     landsat_b \u001b[38;5;241m=\u001b[39m landsat_b\u001b[38;5;241m.\u001b[39mfillna(landsat_b\u001b[38;5;241m.\u001b[39mmean())\n\u001b[1;32m     34\u001b[0m     landsat_g \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/geolifeclef-2024/PA-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset\u001b[38;5;241m.\u001b[39mtitle()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-landsat_time_series/GLC24-PA-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-landsat_time_series-green.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m~/miniconda3/envs/pt/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n","File \u001b[0;32m~/miniconda3/envs/pt/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n","File \u001b[0;32m~/miniconda3/envs/pt/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n","File \u001b[0;32m~/miniconda3/envs/pt/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n","File \u001b[0;32m~/miniconda3/envs/pt/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/geolifeclef-2024/PA-Train-landsat_time_series/GLC24-PA-train-landsat_time_series-blue.csv'"]}],"source":["# Train Dataset and DataLoader\n","train_batch_size = 64\n","train_transform = transforms.Compose([\n","    transforms.Resize((128,128)),\n","    transforms.ToTensor()\n","])\n","\n","# Load Training metadata\n","train_metadata_path = \"data/geolifeclef-2024/GLC24_PA_metadata_train.csv\"\n","train_metadata = pd.read_csv(train_metadata_path)\n","train_dataset = TrainDataset(train_metadata, transform=train_transform)\n","train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=False, num_workers=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2024-04-30T21:25:34.532017Z","start_time":"2024-04-30T21:25:32.615562Z"},"collapsed":false,"execution":{"iopub.execute_input":"2024-05-14T10:49:37.552329Z","iopub.status.busy":"2024-05-14T10:49:37.552041Z","iopub.status.idle":"2024-05-14T10:49:39.402432Z","shell.execute_reply":"2024-05-14T10:49:39.401579Z","shell.execute_reply.started":"2024-05-14T10:49:37.552306Z"},"jupyter":{"outputs_hidden":false},"tags":[],"trusted":true},"outputs":[],"source":["# Test Dataset and DataLoader\n","test_batch_size = 1\n","test_transform = transforms.Compose([\n","    transforms.Resize((128,128)),\n","    transforms.ToTensor()\n","])\n","\n","# Load Testing metadata\n","test_metadata_path = \"data/geolifeclef-2024/GLC24_PA_metadata_test.csv\"\n","test_metadata = pd.read_csv(test_metadata_path)\n","test_dataset = TestDataset(test_metadata, transform=test_transform)\n","test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, num_workers=1)"]},{"cell_type":"markdown","metadata":{},"source":["This is an MLP used to extract features from generally independent information."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T10:49:39.403991Z","iopub.status.busy":"2024-05-14T10:49:39.403704Z","iopub.status.idle":"2024-05-14T10:49:39.410141Z","shell.execute_reply":"2024-05-14T10:49:39.409123Z","shell.execute_reply.started":"2024-05-14T10:49:39.403967Z"},"trusted":true},"outputs":[],"source":["class Embedding(nn.Module):\n","    def __init__(self, dim, out_dim):\n","        super().__init__()\n","        self.fc1 = nn.Linear(dim, out_dim*5)\n","        self.fc2 = nn.Linear(out_dim*5, out_dim)\n","        self.norm = nn.LayerNorm(out_dim*5)\n","\n","    def forward(self, x):\n","        x = F.tanh(self.fc1(x))\n","        x = self.norm(x)\n","        x = self.fc2(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["The following is the part of ViT, which can also be considered as the Encoder part of **Transformer**."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T10:49:39.411749Z","iopub.status.busy":"2024-05-14T10:49:39.411476Z","iopub.status.idle":"2024-05-14T10:49:39.421368Z","shell.execute_reply":"2024-05-14T10:49:39.420625Z","shell.execute_reply.started":"2024-05-14T10:49:39.411726Z"},"trusted":true},"outputs":[],"source":["class Multihead_self_attention(nn.Module):\n","    def __init__(self, heads, head_dim, dim):\n","        super().__init__()\n","        self.head_dim = head_dim\n","        self.heads = heads\n","        self.inner_dim = self.heads*self.head_dim\n","        self.scale = self.head_dim**-0.5\n","        self.to_qkv = nn.Linear(dim, self.inner_dim*3)\n","        self.to_output = nn.Linear(self.inner_dim, dim)\n","        self.norm = nn.LayerNorm(dim)\n","        self.softmax = nn.Softmax(dim=-1)\n","\n","    def forward(self, x):\n","        x = self.norm(x)\n","        qkv = self.to_qkv(x).chunk(3, dim=-1)\n","        Q, K, V = map(lambda t: rearrange(t, 'b l (h dim) -> b h l dim', dim=self.head_dim), qkv)\n","        K_T = K.transpose(-1, -2)\n","        att_score = Q@K_T*self.scale\n","        att = self.softmax(att_score)\n","        out = att@V   # (B,H,L,dim)\n","        out = rearrange(out, 'b h l dim -> b l (h dim)')\n","        output = self.to_output(out)\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T10:49:39.426028Z","iopub.status.busy":"2024-05-14T10:49:39.425343Z","iopub.status.idle":"2024-05-14T10:49:39.434703Z","shell.execute_reply":"2024-05-14T10:49:39.433768Z","shell.execute_reply.started":"2024-05-14T10:49:39.426004Z"},"trusted":true},"outputs":[],"source":["class FeedForward(nn.Module):\n","    def __init__(self, dim, mlp_dim):\n","        super().__init__()\n","        self.fc1 = nn.Linear(dim, mlp_dim)\n","        self.fc2 = nn.Linear(mlp_dim, dim)\n","        self.norm = nn.LayerNorm(dim)\n","\n","    def forward(self, x):\n","        x = self.norm(x)\n","        x = F.gelu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T10:49:39.436189Z","iopub.status.busy":"2024-05-14T10:49:39.435831Z","iopub.status.idle":"2024-05-14T10:49:39.445205Z","shell.execute_reply":"2024-05-14T10:49:39.444308Z","shell.execute_reply.started":"2024-05-14T10:49:39.436134Z"},"trusted":true},"outputs":[],"source":["class Transformer_block(nn.Module):\n","    def __init__(self, dim, heads, head_dim, mlp_dim):\n","        super().__init__()\n","        self.MHA = Multihead_self_attention(heads=heads, head_dim=head_dim, dim=dim)\n","        self.FeedForward = FeedForward(dim=dim, mlp_dim=mlp_dim)\n","\n","    def forward(self, x):\n","        x = self.MHA(x)+x\n","        x = self.FeedForward(x)+x\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T10:49:39.446724Z","iopub.status.busy":"2024-05-14T10:49:39.446405Z","iopub.status.idle":"2024-05-14T10:49:39.454897Z","shell.execute_reply":"2024-05-14T10:49:39.454002Z","shell.execute_reply.started":"2024-05-14T10:49:39.446700Z"},"trusted":true},"outputs":[],"source":["class ViT(nn.Module):\n","    def __init__(self, dim, heads, head_dim, mlp_dim, num_class):\n","        super().__init__()\n","        self.transformer = Transformer_block(dim=dim, heads=heads, head_dim=head_dim, mlp_dim=mlp_dim)\n","\n","        self.MLP_head = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, num_class)\n","        )\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = self.transformer(x)\n","        CLS_token = x[:, 0, :]\n","        out = self.MLP_head(CLS_token)\n","        return out"]},{"cell_type":"markdown","metadata":{},"source":["The following is **CNN**, used to extract feature information from images."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T10:49:39.456231Z","iopub.status.busy":"2024-05-14T10:49:39.455956Z","iopub.status.idle":"2024-05-14T10:49:39.468995Z","shell.execute_reply":"2024-05-14T10:49:39.468140Z","shell.execute_reply.started":"2024-05-14T10:49:39.456207Z"},"trusted":true},"outputs":[],"source":["class ResNet18(nn.Module):\n","    def __init__(self, num_classes):\n","        super(ResNet18, self).__init__()\n","\n","        self.resnet18 = models.resnet18(weights=None)\n","        self.resnet18.conv1 = nn.Conv2d(4, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.resnet18.maxpool = nn.Identity()\n","        self.ln = nn.LayerNorm(1000)\n","        self.fc1 = nn.Linear(1000, num_classes)\n","\n","    def forward(self, x):\n","        x = self.resnet18(x)\n","        x = self.ln(x)\n","        x = self.fc1(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["This is the **final multi-modal model**. Unlike ViT, its input is features extracted from each dimension. \n","\n","For features with time information, I added additional position information. \n","\n","At the same time, I also added a feature that is a fusion of the first four features."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T10:49:39.470238Z","iopub.status.busy":"2024-05-14T10:49:39.469966Z","iopub.status.idle":"2024-05-14T10:49:39.482455Z","shell.execute_reply":"2024-05-14T10:49:39.481712Z","shell.execute_reply.started":"2024-05-14T10:49:39.470215Z"},"trusted":true},"outputs":[],"source":["class MultiModal(nn.Module):\n","    def __init__(self, num_classes):\n","        super(MultiModal, self).__init__()\n","        self.cls = nn.Parameter(torch.randn(1, 1, 200))\n","        self.meta = Embedding(31,200)\n","        self.resnet18 = ResNet18(200)\n","        self.landsat = Embedding(504,200)\n","        self.position_landsat = nn.Parameter(torch.randn(1, 504))\n","        self.climate = Embedding(931,200)\n","        self.position_climate = nn.Parameter(torch.randn(1, 931))\n","        self.emb = Embedding(800,200)\n","        self.position_combine = nn.Parameter(torch.randn(1, 800))\n","        self.vit = ViT(200, 2, 200, 400, num_classes)\n","        self.position = nn.Parameter(torch.randn(1, 6, 200))\n","\n","    def forward(self, x):\n","        batch = x[0].size(0)\n","        CLS = repeat(self.cls, '1 1 d -> b 1 d', b=batch).to(device)\n","        META = self.meta(x[0])\n","        IMG = self.resnet18(x[1])\n","        LANDSAT = self.landsat(x[2]+self.position_landsat)\n","        CLIMATE = self.climate(x[3]+self.position_climate)\n","        combine = torch.cat((META, IMG, LANDSAT, CLIMATE), dim=1)\n","        COMBINE = self.emb(combine+self.position_combine)\n","        token = torch.concat((CLS, META.unsqueeze(1)), dim=1)\n","        token = torch.concat((token, IMG.unsqueeze(1)), dim=1)\n","        token = torch.concat((token, LANDSAT.unsqueeze(1)), dim=1)\n","        token = torch.concat((token, CLIMATE.unsqueeze(1)), dim=1)\n","        token = torch.concat((token, COMBINE.unsqueeze(1)), dim=1)\n","        out = self.vit(token+self.position)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2024-04-30T21:25:31.611823Z","start_time":"2024-04-30T21:25:31.607373Z"},"collapsed":false,"execution":{"iopub.execute_input":"2024-05-14T10:49:39.484305Z","iopub.status.busy":"2024-05-14T10:49:39.483422Z","iopub.status.idle":"2024-05-14T10:49:39.941389Z","shell.execute_reply":"2024-05-14T10:49:39.940572Z","shell.execute_reply.started":"2024-05-14T10:49:39.484275Z"},"jupyter":{"outputs_hidden":false},"tags":[],"trusted":true},"outputs":[],"source":["# Check if cuda is available\n","device = torch.device(\"cpu\")\n","\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(\"DEVICE = CUDA\")\n","\n","model = MultiModal(num_classes).to(device)\n","# model.load_state_dict(torch.load(\"models/multimodal-vit/Model.pth\", map_location=device))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T10:49:39.943241Z","iopub.status.busy":"2024-05-14T10:49:39.942579Z","iopub.status.idle":"2024-05-14T10:49:39.949766Z","shell.execute_reply":"2024-05-14T10:49:39.948820Z","shell.execute_reply.started":"2024-05-14T10:49:39.943207Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/startung/miniconda3/envs/pt/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"]}],"source":["optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","scheduler = CosineAnnealingLR(optimizer, T_max=25, verbose=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T10:49:39.951152Z","iopub.status.busy":"2024-05-14T10:49:39.950912Z","iopub.status.idle":"2024-05-14T12:20:42.436329Z","shell.execute_reply":"2024-05-14T12:20:42.435076Z","shell.execute_reply.started":"2024-05-14T10:49:39.951131Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training for 1 epochs started.\n","Epoch 1/1, Batch 0/23182, Loss: 0.7361268997192383\n"]}],"source":["print(f\"Training for {num_epochs} epochs started.\")\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","\n","    for batch_idx, (sample, survey_id, labels) in enumerate(train_loader):\n","        samples = [tensor.to(device) for tensor in sample]\n","        survey_id = survey_id.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(samples)\n","\n","        pos_weight = labels*positive_weigh_factor  # All positive weights are equal to 10\n","        criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n","        loss = criterion(outputs, labels)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch_idx % 278 == 0:\n","            print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item()}\")\n","\n","    scheduler.step()\n","    print(\"Scheduler:\",scheduler.state_dict())\n","\n","# Save the trained model\n","model.eval()\n","torch.save(model.state_dict(), \"multimodal-model.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T12:20:42.438418Z","iopub.status.busy":"2024-05-14T12:20:42.438071Z","iopub.status.idle":"2024-05-14T12:22:33.041854Z","shell.execute_reply":"2024-05-14T12:22:33.040577Z","shell.execute_reply.started":"2024-05-14T12:20:42.438384Z"},"trusted":true},"outputs":[],"source":["with torch.no_grad():\n","    surveys = []\n","    top_indices = []\n","    for data, surveyID in tqdm.tqdm(test_loader, total=len(test_loader)):\n","\n","        data = [tensor.to(device) for tensor in data]\n","\n","        outputs = model(data)\n","        predictions = torch.sigmoid(outputs).cpu().numpy()\n","        predictions = np.squeeze(predictions)\n","#         prediction = np.argwhere(predictions>0).flatten()\n","        top_indices.append(predictions)\n","        surveys.extend(surveyID.cpu().numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"start_time":"2024-04-30T21:25:34.536634Z"},"collapsed":false,"execution":{"iopub.execute_input":"2024-05-14T12:22:33.044097Z","iopub.status.busy":"2024-05-14T12:22:33.043705Z","iopub.status.idle":"2024-05-14T12:22:33.049278Z","shell.execute_reply":"2024-05-14T12:22:33.048423Z","shell.execute_reply.started":"2024-05-14T12:22:33.044060Z"},"is_executing":true,"jupyter":{"outputs_hidden":false},"tags":[],"trusted":true},"outputs":[],"source":["# with torch.no_grad():\n","#     surveys = []\n","#     top_indices = []\n","#     for data, surveyID in tqdm.tqdm(test_loader, total=len(test_loader)):\n","\n","#         data = [tensor.to(device) for tensor in data]\n","\n","#         outputs = model(data)\n","#         predictions = torch.sigmoid(outputs).cpu().numpy()\n","#         predictions = np.squeeze(predictions)\n","#         prediction = np.argwhere(predictions>=0.95).flatten()\n","#         top_indices.append(prediction)\n","#         surveys.extend(surveyID.cpu().numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T12:22:33.051657Z","iopub.status.busy":"2024-05-14T12:22:33.050516Z","iopub.status.idle":"2024-05-14T12:23:02.738682Z","shell.execute_reply":"2024-05-14T12:23:02.737864Z","shell.execute_reply.started":"2024-05-14T12:22:33.051624Z"},"trusted":true},"outputs":[],"source":["pd.DataFrame(top_indices).add_prefix(\"speciesId_\").to_pickle(\"vit.pkl\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T12:23:02.740150Z","iopub.status.busy":"2024-05-14T12:23:02.739860Z","iopub.status.idle":"2024-05-14T12:23:02.744098Z","shell.execute_reply":"2024-05-14T12:23:02.743175Z","shell.execute_reply.started":"2024-05-14T12:23:02.740127Z"},"trusted":true},"outputs":[],"source":["# data_concatenated = [' '.join(map(str, row)) for row in top_indices]\n","\n","# pd.DataFrame(\n","#     {'surveyId': surveys,\n","#      'predictions': data_concatenated,\n","#     }).to_csv(\"submission3.csv\", index = False)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":8171035,"sourceId":64733,"sourceType":"competition"},{"modelInstanceId":36765,"sourceId":43782,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
