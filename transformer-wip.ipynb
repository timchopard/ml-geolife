{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T15:00:27.681592Z","iopub.status.busy":"2024-05-15T15:00:27.681121Z","iopub.status.idle":"2024-05-15T15:00:39.663233Z","shell.execute_reply":"2024-05-15T15:00:39.662055Z","shell.execute_reply.started":"2024-05-15T15:00:27.681548Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: einops in /home/startung/miniconda3/envs/pt/lib/python3.11/site-packages (0.8.0)\n"]}],"source":["! pip install einops"]},{"cell_type":"code","execution_count":2,"metadata":{"ExecuteTime":{"end_time":"2024-04-30T21:25:07.29831Z","start_time":"2024-04-30T21:25:05.354584Z"},"execution":{"iopub.execute_input":"2024-05-15T15:00:39.665766Z","iopub.status.busy":"2024-05-15T15:00:39.665455Z","iopub.status.idle":"2024-05-15T15:00:39.672586Z","shell.execute_reply":"2024-05-15T15:00:39.671721Z","shell.execute_reply.started":"2024-05-15T15:00:39.665738Z"},"tags":[],"trusted":true},"outputs":[],"source":["import os\n","import torch\n","import tqdm\n","import numpy as np\n","import pandas as pd\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from sklearn.metrics import precision_recall_fscore_support\n","from PIL import Image\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from einops.layers.torch import Rearrange\n","from einops import rearrange, repeat\n","import time"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T15:00:39.673967Z","iopub.status.busy":"2024-05-15T15:00:39.673708Z","iopub.status.idle":"2024-05-15T15:00:39.686591Z","shell.execute_reply":"2024-05-15T15:00:39.685696Z","shell.execute_reply.started":"2024-05-15T15:00:39.673945Z"},"trusted":true},"outputs":[],"source":["# Hyperparameters\n","learning_rate = 0.00025\n","num_epochs = 1\n","positive_weigh_factor = 1.0\n","INITIAL_SEED = 113\n","test_batch_size = 1\n","train_batch_size = 64\n","num_classes = 11255 # max 11255\n","vit_path = None #\"models/multimodal-vit/Model.pth\"\n","data_root = \"data\" #\"/kaggle/input\""]},{"cell_type":"markdown","metadata":{},"source":["When reading data, different **fusion** and **normalization** will be performed for different types of data."]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T15:00:39.689367Z","iopub.status.busy":"2024-05-15T15:00:39.689093Z","iopub.status.idle":"2024-05-15T15:00:39.716733Z","shell.execute_reply":"2024-05-15T15:00:39.715939Z","shell.execute_reply.started":"2024-05-15T15:00:39.689322Z"},"trusted":true},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, subset):\n","        self.subset = subset\n","        self.metadata_path = f\"{data_root}/geolifeclef-2024/GLC24_PA_metadata_{self.subset}.csv\"\n","        self.metadata = pd.read_csv(self.metadata_path)\n","        self.transform = transforms.Compose([transforms.Resize((128,128)), transforms.ToTensor()])\n","        self.merge_key = 'surveyId'\n","\n","        self.metadata_data = self.Norm(self.process_metadata())\n","        self.climate_data = self.Norm_all(self.process_climate())\n","        self.landsat_data = self.process_landsat()\n","        self.elevation_data = self.Norm(self.process_elevation())\n","        self.human_footprint_data = self.Norm(self.process_human_footprint())\n","        self.landcover_data = self.Norm(self.process_landcover())\n","        self.soilgrids_data = self.Norm(self.process_soilgrids())\n","        self.metadata_data = torch.cat((self.metadata_data, self.elevation_data, self.human_footprint_data, self.landcover_data, self.soilgrids_data), dim=1)\n","\n","    def process_metadata(self):\n","        metadata = self.metadata.drop_duplicates(subset=\"surveyId\").reset_index(drop=True).copy()\n","        metadata.fillna(0,inplace=True)\n","        metadata.replace({float('-inf'): 0}, inplace=True)\n","        return metadata.iloc[:,:5]\n","\n","    def process_climate(self):\n","        climate_average = pd.read_csv(f\"{data_root}/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/Climate/Average 1981-2010/GLC24-PA-{self.subset}-bioclimatic.csv\")\n","        climate_monthly = pd.read_csv(f\"{data_root}/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/Climate/Monthly/GLC24-PA-{self.subset}-bioclimatic_monthly.csv\")\n","        climate = pd.merge(climate_average, climate_monthly, on=self.merge_key)\n","        climate.fillna(climate.mean(),inplace=True)\n","        return climate\n","\n","    def process_landsat(self):\n","        landsat_types = ['blue', 'green', 'red', 'nir', 'swir1', 'swir2']\n","        landsat_dfs = []\n","        for landsat_type in landsat_types:\n","            landsat = pd.read_csv(f\"{data_root}/geolifeclef-2024/PA-{self.subset}-landsat_time_series/GLC24-PA-{self.subset}-landsat_time_series-{landsat_type}.csv\")\n","            landsat.fillna(landsat.mean(),inplace=True)\n","            landsat_dfs.append(landsat)\n","        return torch.cat([self.Norm_all(landsat_df) for landsat_df in landsat_dfs],axis=1)\n","\n","    def process_elevation(self):\n","        elevation = pd.read_csv(f\"{data_root}/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/Elevation/GLC24-PA-{self.subset}-elevation.csv\")\n","        elevation[elevation<0]=0\n","        elevation.fillna(elevation.mean(),inplace=True)\n","        return elevation\n","\n","    def process_human_footprint(self):\n","        human_footprint = pd.read_csv(f\"{data_root}/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/Human Footprint/GLC24-PA-{self.subset}-human_footprint.csv\")\n","        human_footprint[human_footprint<0]=0\n","        human_footprint.fillna(human_footprint.mean(),inplace=True)\n","        return human_footprint\n","\n","    def process_landcover(self):\n","        landcover = pd.read_csv(f\"{data_root}/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/LandCover/GLC24-PA-{self.subset}-landcover.csv\")\n","        landcover[landcover<0]=0\n","        landcover.fillna(landcover.mean(),inplace=True)\n","        return landcover\n","\n","    def process_soilgrids(self):\n","        soilgrids = pd.read_csv(f\"{data_root}/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/SoilGrids/GLC24-PA-{self.subset}-soilgrids.csv\")\n","        soilgrids[soilgrids<0]=0\n","        soilgrids.fillna(soilgrids.mean(),inplace=True)\n","        return soilgrids\n","\n","    def Norm(self,df):\n","        output=torch.from_numpy(df.iloc[:,1:].values).float()\n","        return (output-output.mean(dim=0))/output.std(dim=0)\n","\n","    def Norm_all(self,df):\n","        output=torch.from_numpy(df.iloc[:,1:].values).float()\n","        return (output-output.mean())/output.std()\n","\n","    def patch_rgb_path(self,survey_id):\n","        path = f\"{data_root}/geolifeclef-2024/PA_{self.subset.title()}_SatellitePatches_RGB/pa_{self.subset}_patches_rgb\"\n","        for d in (str(survey_id)[-2:], str(survey_id)[-4:-2]):\n","            path = os.path.join(path, d)\n","        path = os.path.join(path, f\"{survey_id}.jpeg\")\n","        return path\n","\n","    def patch_nir_path(self,survey_id):\n","        path = f\"{data_root}/geolifeclef-2024/PA_{self.subset.title()}_SatellitePatches_NIR/pa_{self.subset}_patches_nir\"\n","        for d in (str(survey_id)[-2:], str(survey_id)[-4:-2]):\n","            path = os.path.join(path, d)\n","        path = os.path.join(path, f\"{survey_id}.jpeg\")\n","        return path\n","\n","    def __len__(self):\n","        return len(self.metadata)\n","\n","    def __getitem__(self, idx):\n","        survey_id = self.metadata.surveyId[idx]\n","        image_path = self.patch_rgb_path(survey_id)\n","        image = Image.open(image_path).convert(\"RGB\")\n","        image = self.transform(image)\n","        image = image.unsqueeze(0)\n","        image_nir_path = self.patch_nir_path(survey_id)\n","        nir_image = Image.open(image_nir_path).convert(\"L\")\n","        nir_image = self.transform(nir_image)\n","        nir_image = nir_image.unsqueeze(0)\n","        image_data = torch.cat([image,nir_image],dim=1)\n","        image_data = torch.squeeze(image_data)\n","        sample=[self.metadata_data[idx,:],image_data,self.landsat_data[idx,:],self.climate_data[idx,:]]\n","        return sample, survey_id"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T15:00:39.718453Z","iopub.status.busy":"2024-05-15T15:00:39.717846Z","iopub.status.idle":"2024-05-15T15:00:39.730153Z","shell.execute_reply":"2024-05-15T15:00:39.729383Z","shell.execute_reply.started":"2024-05-15T15:00:39.718423Z"},"trusted":true},"outputs":[],"source":["class TestDataset(CustomDataset):\n","    def __init__(self):\n","        super().__init__(subset=\"test\")\n","\n","    def __getitem__(self, idx):\n","        sample, survey_id = super().__getitem__(idx)\n","        return sample, survey_id"]},{"cell_type":"code","execution_count":6,"metadata":{"ExecuteTime":{"end_time":"2024-04-30T21:25:32.627928Z","start_time":"2024-04-30T21:25:32.612131Z"},"collapsed":false,"execution":{"iopub.execute_input":"2024-05-15T15:00:39.732002Z","iopub.status.busy":"2024-05-15T15:00:39.731493Z","iopub.status.idle":"2024-05-15T15:00:39.760792Z","shell.execute_reply":"2024-05-15T15:00:39.759898Z","shell.execute_reply.started":"2024-05-15T15:00:39.731971Z"},"jupyter":{"outputs_hidden":false},"tags":[],"trusted":true},"outputs":[],"source":["class TrainDataset(CustomDataset):\n","    def __init__(self):\n","        super().__init__(subset=\"train\")\n","\n","        labels = self.metadata[['surveyId' ,'speciesId']].astype(int).copy()\n","        print(labels.shape)\n","        self.label_dict = labels.groupby('surveyId')['speciesId'].apply(list).to_dict()\n","        print(len(self.label_dict))\n","\n","\n","    def __getitem__(self, idx):\n","        sample, survey_id = super().__getitem__(idx)\n","        # species_ids = self.label_dict.get(survey_id, [])  # Get list of species IDs for the survey ID\n","        species_ids = self.label_dict[survey_id]  # Get list of species IDs for the survey ID\n","        label = torch.zeros(num_classes)  # Initialize label tensor\n","        for species_id in species_ids:\n","            label_id = species_id\n","            label[label_id] = 1  # Set the corresponding class index to 1 for each species\n","        return sample, survey_id, label"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T15:00:39.762068Z","iopub.status.busy":"2024-05-15T15:00:39.761819Z","iopub.status.idle":"2024-05-15T15:01:03.183069Z","shell.execute_reply":"2024-05-15T15:01:03.182017Z","shell.execute_reply.started":"2024-05-15T15:00:39.762047Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(1483637, 2)\n","88987\n"]}],"source":["train_dataset, val_dataset = torch.utils.data.random_split(TrainDataset(), [0.8, 0.2])\n","test_dataset = TestDataset()\n","\n","dataloaders = {'train': DataLoader(train_dataset, batch_size=train_batch_size, shuffle=False, num_workers=1),\n","               'val': DataLoader(val_dataset, batch_size=test_batch_size, shuffle=False, num_workers=1),\n","               'test': DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, num_workers=1)}"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(1483637, 2)\n","88987\n"]}],"source":["test = TrainDataset()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["1483637"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["len(test)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["51 tensor(1.)\n","476 tensor(1.)\n","982 tensor(1.)\n","1304 tensor(1.)\n","2159 tensor(1.)\n","2421 tensor(1.)\n","2932 tensor(1.)\n","3935 tensor(1.)\n","4530 tensor(1.)\n","6874 tensor(1.)\n","8784 tensor(1.)\n","9030 tensor(1.)\n","9458 tensor(1.)\n","10520 tensor(1.)\n","11157 tensor(1.)\n","11193 tensor(1.)\n"]}],"source":["for idx, item in enumerate(test.__getitem__(0)[2]):\n","    if item > 0:\n","        print(idx, item)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["[6874,\n"," 476,\n"," 11157,\n"," 8784,\n"," 4530,\n"," 10520,\n"," 9458,\n"," 982,\n"," 51,\n"," 3935,\n"," 11193,\n"," 2421,\n"," 2159,\n"," 9030,\n"," 2932,\n"," 1304]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["test.label_dict[212]"]},{"cell_type":"markdown","metadata":{},"source":["This is an MLP used to extract features from generally independent information."]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T15:01:05.155485Z","iopub.status.busy":"2024-05-15T15:01:05.155181Z","iopub.status.idle":"2024-05-15T15:01:05.161983Z","shell.execute_reply":"2024-05-15T15:01:05.160806Z","shell.execute_reply.started":"2024-05-15T15:01:05.155461Z"},"trusted":true},"outputs":[],"source":["class Embedding(nn.Module):\n","    def __init__(self, dim, out_dim):\n","        super().__init__()\n","        self.fc1 = nn.Linear(dim, out_dim*5)\n","        self.fc2 = nn.Linear(out_dim*5, out_dim)\n","        self.norm = nn.LayerNorm(out_dim*5)\n","\n","    def forward(self, x):\n","        x = F.tanh(self.fc1(x))\n","        x = self.norm(x)\n","        x = self.fc2(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["The following is the part of ViT, which can also be considered as the Encoder part of **Transformer**."]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T15:01:05.165922Z","iopub.status.busy":"2024-05-15T15:01:05.165653Z","iopub.status.idle":"2024-05-15T15:01:05.175129Z","shell.execute_reply":"2024-05-15T15:01:05.174218Z","shell.execute_reply.started":"2024-05-15T15:01:05.165900Z"},"trusted":true},"outputs":[],"source":["class Multihead_self_attention(nn.Module):\n","    def __init__(self, heads, head_dim, dim):\n","        super().__init__()\n","        self.head_dim = head_dim\n","        self.heads = heads\n","        self.inner_dim = self.heads*self.head_dim\n","        self.scale = self.head_dim**-0.5\n","        self.to_qkv = nn.Linear(dim, self.inner_dim*3)\n","        self.to_output = nn.Linear(self.inner_dim, dim)\n","        self.norm = nn.LayerNorm(dim)\n","        self.softmax = nn.Softmax(dim=-1)\n","\n","    def forward(self, x):\n","        x = self.norm(x)\n","        qkv = self.to_qkv(x).chunk(3, dim=-1)\n","        Q, K, V = map(lambda t: rearrange(t, 'b l (h dim) -> b h l dim', dim=self.head_dim), qkv)\n","        K_T = K.transpose(-1, -2)\n","        att_score = Q@K_T*self.scale\n","        att = self.softmax(att_score)\n","        out = att@V   # (B,H,L,dim)\n","        out = rearrange(out, 'b h l dim -> b l (h dim)')\n","        output = self.to_output(out)\n","        return output"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T15:01:05.177322Z","iopub.status.busy":"2024-05-15T15:01:05.176279Z","iopub.status.idle":"2024-05-15T15:01:05.189312Z","shell.execute_reply":"2024-05-15T15:01:05.188395Z","shell.execute_reply.started":"2024-05-15T15:01:05.177291Z"},"trusted":true},"outputs":[],"source":["class FeedForward(nn.Module):\n","    def __init__(self, dim, mlp_dim):\n","        super().__init__()\n","        self.fc1 = nn.Linear(dim, mlp_dim)\n","        self.fc2 = nn.Linear(mlp_dim, dim)\n","        self.norm = nn.LayerNorm(dim)\n","\n","    def forward(self, x):\n","        x = self.norm(x)\n","        x = F.gelu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T15:01:05.191012Z","iopub.status.busy":"2024-05-15T15:01:05.190663Z","iopub.status.idle":"2024-05-15T15:01:05.198986Z","shell.execute_reply":"2024-05-15T15:01:05.197990Z","shell.execute_reply.started":"2024-05-15T15:01:05.190981Z"},"trusted":true},"outputs":[],"source":["class Transformer_block(nn.Module):\n","    def __init__(self, dim, heads, head_dim, mlp_dim):\n","        super().__init__()\n","        self.MHA = Multihead_self_attention(heads=heads, head_dim=head_dim, dim=dim)\n","        self.FeedForward = FeedForward(dim=dim, mlp_dim=mlp_dim)\n","\n","    def forward(self, x):\n","        x = self.MHA(x)+x\n","        x = self.FeedForward(x)+x\n","        return x"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T15:01:05.200775Z","iopub.status.busy":"2024-05-15T15:01:05.200113Z","iopub.status.idle":"2024-05-15T15:01:05.209842Z","shell.execute_reply":"2024-05-15T15:01:05.209028Z","shell.execute_reply.started":"2024-05-15T15:01:05.200746Z"},"trusted":true},"outputs":[],"source":["class ViT(nn.Module):\n","    def __init__(self, dim, heads, head_dim, mlp_dim, num_class):\n","        super().__init__()\n","        self.transformer = Transformer_block(dim=dim, heads=heads, head_dim=head_dim, mlp_dim=mlp_dim)\n","\n","        self.MLP_head = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, num_class)\n","        )\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = self.transformer(x)\n","        CLS_token = x[:, 0, :]\n","        out = self.MLP_head(CLS_token)\n","        return out"]},{"cell_type":"markdown","metadata":{},"source":["The following is **CNN**, used to extract feature information from images."]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T15:01:05.211040Z","iopub.status.busy":"2024-05-15T15:01:05.210796Z","iopub.status.idle":"2024-05-15T15:01:05.222835Z","shell.execute_reply":"2024-05-15T15:01:05.221946Z","shell.execute_reply.started":"2024-05-15T15:01:05.211019Z"},"trusted":true},"outputs":[],"source":["class ResNet18(nn.Module):\n","    def __init__(self, num_classes):\n","        super(ResNet18, self).__init__()\n","\n","        self.resnet18 = models.resnet18(weights=None)\n","        self.resnet18.conv1 = nn.Conv2d(4, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.resnet18.maxpool = nn.Identity()\n","        self.ln = nn.LayerNorm(1000)\n","        self.fc1 = nn.Linear(1000, num_classes)\n","\n","    def forward(self, x):\n","        x = self.resnet18(x)\n","        x = self.ln(x)\n","        x = self.fc1(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["This is the **final multi-modal model**. Unlike ViT, its input is features extracted from each dimension. \n","\n","For features with time information, I added additional position information. \n","\n","At the same time, I also added a feature that is a fusion of the first four features."]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T15:01:05.224522Z","iopub.status.busy":"2024-05-15T15:01:05.224013Z","iopub.status.idle":"2024-05-15T15:01:05.237375Z","shell.execute_reply":"2024-05-15T15:01:05.236543Z","shell.execute_reply.started":"2024-05-15T15:01:05.224492Z"},"trusted":true},"outputs":[],"source":["class MultiModal(nn.Module):\n","    def __init__(self, num_classes):\n","        super(MultiModal, self).__init__()\n","        self.cls = nn.Parameter(torch.randn(1, 1, 200))\n","        self.meta = Embedding(31,200)\n","        self.resnet18 = ResNet18(200)\n","        self.landsat = Embedding(504,200)\n","        self.position_landsat = nn.Parameter(torch.randn(1, 504))\n","        self.climate = Embedding(931,200)\n","        self.position_climate = nn.Parameter(torch.randn(1, 931))\n","        self.emb = Embedding(800,200)\n","        self.position_combine = nn.Parameter(torch.randn(1, 800))\n","        self.vit = ViT(200, 2, 200, 400, num_classes)\n","        self.position = nn.Parameter(torch.randn(1, 6, 200))\n","\n","    def forward(self, x):\n","        batch = x[0].size(0)\n","        CLS = repeat(self.cls, '1 1 d -> b 1 d', b=batch).to(device)\n","        META = self.meta(x[0])\n","        IMG = self.resnet18(x[1])\n","        LANDSAT = self.landsat(x[2]+self.position_landsat)\n","        CLIMATE = self.climate(x[3]+self.position_climate)\n","        combine = torch.cat((META, IMG, LANDSAT, CLIMATE), dim=1)\n","        COMBINE = self.emb(combine+self.position_combine)\n","        token = torch.concat((CLS, META.unsqueeze(1)), dim=1)\n","        token = torch.concat((token, IMG.unsqueeze(1)), dim=1)\n","        token = torch.concat((token, LANDSAT.unsqueeze(1)), dim=1)\n","        token = torch.concat((token, CLIMATE.unsqueeze(1)), dim=1)\n","        token = torch.concat((token, COMBINE.unsqueeze(1)), dim=1)\n","        out = self.vit(token+self.position)\n","        return out"]},{"cell_type":"code","execution_count":19,"metadata":{"ExecuteTime":{"end_time":"2024-04-30T21:25:31.611823Z","start_time":"2024-04-30T21:25:31.607373Z"},"collapsed":false,"execution":{"iopub.execute_input":"2024-05-15T15:01:05.238529Z","iopub.status.busy":"2024-05-15T15:01:05.238270Z","iopub.status.idle":"2024-05-15T15:01:05.703192Z","shell.execute_reply":"2024-05-15T15:01:05.702329Z","shell.execute_reply.started":"2024-05-15T15:01:05.238508Z"},"jupyter":{"outputs_hidden":false},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DEVICE = CUDA\n","MultiModal(\n","  (meta): Embedding(\n","    (fc1): Linear(in_features=31, out_features=1000, bias=True)\n","    (fc2): Linear(in_features=1000, out_features=200, bias=True)\n","    (norm): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (resnet18): ResNet18(\n","    (resnet18): ResNet(\n","      (conv1): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (maxpool): Identity()\n","      (layer1): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","      (fc): Linear(in_features=512, out_features=1000, bias=True)\n","    )\n","    (ln): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n","    (fc1): Linear(in_features=1000, out_features=200, bias=True)\n","  )\n","  (landsat): Embedding(\n","    (fc1): Linear(in_features=504, out_features=1000, bias=True)\n","    (fc2): Linear(in_features=1000, out_features=200, bias=True)\n","    (norm): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (climate): Embedding(\n","    (fc1): Linear(in_features=931, out_features=1000, bias=True)\n","    (fc2): Linear(in_features=1000, out_features=200, bias=True)\n","    (norm): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (emb): Embedding(\n","    (fc1): Linear(in_features=800, out_features=1000, bias=True)\n","    (fc2): Linear(in_features=1000, out_features=200, bias=True)\n","    (norm): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (vit): ViT(\n","    (transformer): Transformer_block(\n","      (MHA): Multihead_self_attention(\n","        (to_qkv): Linear(in_features=200, out_features=1200, bias=True)\n","        (to_output): Linear(in_features=400, out_features=200, bias=True)\n","        (norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","        (softmax): Softmax(dim=-1)\n","      )\n","      (FeedForward): FeedForward(\n","        (fc1): Linear(in_features=200, out_features=400, bias=True)\n","        (fc2): Linear(in_features=400, out_features=200, bias=True)\n","        (norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (MLP_head): Sequential(\n","      (0): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","      (1): Linear(in_features=200, out_features=11255, bias=True)\n","    )\n","    (sigmoid): Sigmoid()\n","  )\n",")\n"]}],"source":["# Check if cuda is available\n","device = torch.device(\"cpu\")\n","\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(\"DEVICE = CUDA\")\n","\n","model = MultiModal(num_classes).to(device)\n","# print(model)\n","# model.load_state_dict(torch.load(\"models/multimodal-vit/Model.pth\", map_location=device))"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T15:01:05.704772Z","iopub.status.busy":"2024-05-15T15:01:05.704415Z","iopub.status.idle":"2024-05-15T15:01:05.711529Z","shell.execute_reply":"2024-05-15T15:01:05.710601Z","shell.execute_reply.started":"2024-05-15T15:01:05.704740Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/startung/miniconda3/envs/pt/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"]}],"source":["optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","scheduler = CosineAnnealingLR(optimizer, T_max=25, verbose=True)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T15:01:05.713496Z","iopub.status.busy":"2024-05-15T15:01:05.712662Z","iopub.status.idle":"2024-05-15T15:36:42.108010Z","shell.execute_reply":"2024-05-15T15:36:42.106883Z","shell.execute_reply.started":"2024-05-15T15:01:05.713471Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training for 1 epochs started.\n"]},{"ename":"IndexError","evalue":"Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/startung/miniconda3/envs/pt/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/startung/miniconda3/envs/pt/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/startung/miniconda3/envs/pt/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 399, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/startung/miniconda3/envs/pt/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 399, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_297742/1441425558.py\", line 12, in __getitem__\n    sample, survey_id = super().__getitem__(idx)\n                        ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_297742/848438133.py\", line 101, in __getitem__\n    sample=[self.metadata_data[idx,:],image_data,self.landsat_data[idx,:],self.climate_data[idx,:]]\n            ~~~~~~~~~~~~~~~~~~^^^^^^^\nIndexError: index 764818 is out of bounds for dimension 0 with size 88987\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# running_loss = 0.0\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# running_corrects = 0\u001b[39;00m\n\u001b[1;32m     13\u001b[0m f1_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (sample, survey_id, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloaders[phase]):\n\u001b[1;32m     16\u001b[0m     samples \u001b[38;5;241m=\u001b[39m [tensor\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m sample]\n\u001b[1;32m     17\u001b[0m     survey_id \u001b[38;5;241m=\u001b[39m survey_id\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[0;32m~/miniconda3/envs/pt/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/miniconda3/envs/pt/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n","File \u001b[0;32m~/miniconda3/envs/pt/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     data\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n","File \u001b[0;32m~/miniconda3/envs/pt/lib/python3.11/site-packages/torch/_utils.py:722\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 722\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n","\u001b[0;31mIndexError\u001b[0m: Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/startung/miniconda3/envs/pt/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/startung/miniconda3/envs/pt/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/startung/miniconda3/envs/pt/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 399, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/startung/miniconda3/envs/pt/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 399, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_297742/1441425558.py\", line 12, in __getitem__\n    sample, survey_id = super().__getitem__(idx)\n                        ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_297742/848438133.py\", line 101, in __getitem__\n    sample=[self.metadata_data[idx,:],image_data,self.landsat_data[idx,:],self.climate_data[idx,:]]\n            ~~~~~~~~~~~~~~~~~~^^^^^^^\nIndexError: index 764818 is out of bounds for dimension 0 with size 88987\n"]}],"source":["print(f\"Training for {num_epochs} epochs started.\")\n","start_time = time.time()\n","\n","for epoch in range(num_epochs):\n","    for phase in ['val']:\n","        if phase == 'train':\n","            model.train()\n","        else:\n","            model.eval()\n","\n","        # running_loss = 0.0\n","        # running_corrects = 0\n","        f1_scores = []\n","\n","        for batch_idx, (sample, survey_id, labels) in enumerate(dataloaders[phase]):\n","            samples = [tensor.to(device) for tensor in sample]\n","            survey_id = survey_id.to(device)\n","            labels = labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            with torch.set_grad_enabled(phase == 'train'):\n","                outputs = model(samples)\n","                pos_weight = labels*positive_weigh_factor  # All positive weights are equal to 10\n","                criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n","                loss = criterion(outputs, labels)\n","\n","                if phase == 'train':\n","                    loss.backward()\n","                    optimizer.step()\n","            # running_loss += loss.item() * len(sample)\n","            # running_corrects += torch.sum(outputs == labels.data)\n","\n","            if phase == 'train':\n","                if batch_idx % (len(dataloaders[phase])//10) == 0:\n","                    print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(dataloaders[phase])}, Loss: {loss.item()}\")\n","            else:\n","                if batch_idx % (len(dataloaders[phase])//10) == 1:\n","                    print(f\"{outputs.cpu().detach().numpy()=}\")\n","                    print(f\"{labels.cpu().detach().numpy().squeeze().sum()=}\")\n","                    print(f\"{labels.cpu().detach().numpy().squeeze()>0.5=}\")\n","                # f1_scores.append(precision_recall_fscore_support(outputs.cpu(), labels.cpu(), average='micro'))\n","\n","\n","        if phase == 'train':\n","            scheduler.step()\n","\n","        # epoch_loss = running_loss / len(dataloaders[phase])\n","        # epoch_acc = running_corrects.double() / len(dataloaders[phase])\n","\n","        # print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","        if phase == 'val':\n","            print(f\"Epoch {epoch+1}/{num_epochs}, F1 Score: {np.mean(f1_scores)}\")\n","\n","        print(\"Scheduler:\",scheduler.state_dict())\n","print(f\"Training time: {(time.time()-start_time)/60:.0f} minutes\")\n","# Save the trained model\n","model.eval()\n","torch.save(model.state_dict(), \"multimodal-model.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T15:36:42.110210Z","iopub.status.busy":"2024-05-15T15:36:42.109820Z","iopub.status.idle":"2024-05-15T15:43:48.887362Z","shell.execute_reply":"2024-05-15T15:43:48.886244Z","shell.execute_reply.started":"2024-05-15T15:36:42.110171Z"},"trusted":true},"outputs":[],"source":["with torch.no_grad():\n","    surveys = []\n","    top_indices = []\n","    for data, surveyID in tqdm.tqdm(dataloaders['test'], total=len(dataloaders['test'])):\n","\n","        data = [tensor.to(device) for tensor in data]\n","\n","        outputs = model(data)\n","        predictions = torch.sigmoid(outputs).cpu().numpy()\n","        predictions = np.squeeze(predictions)\n","        top_indices.append(predictions)\n","        surveys.extend(surveyID.cpu().numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T15:43:48.895118Z","iopub.status.busy":"2024-05-15T15:43:48.894789Z","iopub.status.idle":"2024-05-15T15:44:18.206909Z","shell.execute_reply":"2024-05-15T15:44:18.206048Z","shell.execute_reply.started":"2024-05-15T15:43:48.895088Z"},"trusted":true},"outputs":[],"source":["pd.DataFrame(top_indices).add_prefix(\"speciesId_\").to_pickle(\"vit.pkl\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":8171035,"sourceId":64733,"sourceType":"competition"},{"modelInstanceId":36765,"sourceId":43782,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":4}
