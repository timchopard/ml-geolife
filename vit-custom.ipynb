{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17159bbd",
   "metadata": {
    "papermill": {
     "duration": 0.006704,
     "end_time": "2024-05-05T14:42:28.165291",
     "exception": false,
     "start_time": "2024-05-05T14:42:28.158587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# This is an INFERENCE using the model combine the method of MLP, CNN and Transformer\n",
    "\n",
    "Thanks PICEKL for his baseline, which help me a lot.\n",
    "\n",
    "The main idea of this method is to obtain multiple features from multiple dimensions. We simply divide it into four types: **image information** with spatial characteristics, **meta information** that is independent of each other, **climate information** and **satellite information** with time characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a1703a0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T21:25:07.29831Z",
     "start_time": "2024-04-30T21:25:05.354584Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-05T14:42:41.363659Z",
     "iopub.status.busy": "2024-05-05T14:42:41.363369Z",
     "iopub.status.idle": "2024-05-05T14:42:49.299669Z",
     "shell.execute_reply": "2024-05-05T14:42:49.298878Z"
    },
    "papermill": {
     "duration": 7.946835,
     "end_time": "2024-05-05T14:42:49.302146",
     "exception": false,
     "start_time": "2024-05-05T14:42:41.355311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from PIL import Image\n",
    "from einops import repeat\n",
    "from pathlib import Path\n",
    "import time\n",
    "from models2 import ViT, MLP, ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1faf2acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir = Path(\"output\") / time.strftime('%Y-%m-%d_%H%M', time.localtime())\n",
    "new_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c275e9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T14:42:49.317022Z",
     "iopub.status.busy": "2024-05-05T14:42:49.316581Z",
     "iopub.status.idle": "2024-05-05T14:42:49.320755Z",
     "shell.execute_reply": "2024-05-05T14:42:49.319956Z"
    },
    "papermill": {
     "duration": 0.013539,
     "end_time": "2024-05-05T14:42:49.322641",
     "exception": false,
     "start_time": "2024-05-05T14:42:49.309102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_classes = 11255\n",
    "num_epochs = 10\n",
    "seed = 113"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f91a65",
   "metadata": {
    "papermill": {
     "duration": 0.006362,
     "end_time": "2024-05-05T14:42:49.335533",
     "exception": false,
     "start_time": "2024-05-05T14:42:49.329171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When reading data, different **fusion** and **normalization** will be performed for different types of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ccd14039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7afe6442bd10>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9782ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, metadata, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "        self.metadata = metadata\n",
    "\n",
    "        labels = self.metadata[['surveyId' ,'speciesId']].astype(int).copy()\n",
    "        self.label_dict = labels.groupby('surveyId')['speciesId'].apply(list).to_dict()\n",
    "\n",
    "        self.metadata = self.metadata.drop_duplicates(subset=\"surveyId\").reset_index(drop=True)\n",
    "        self.metadata.fillna(0,inplace=True)\n",
    "        self.metadata.replace({float('-inf'): 0}, inplace=True)\n",
    "        self.metadata_data = self.Norm(self.metadata.iloc[:,:5])\n",
    "\n",
    "        self.merge_key = 'surveyId'\n",
    "        self.climate_average = pd.read_csv(\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/Climate/Average 1981-2010/GLC24-PA-train-bioclimatic.csv\")\n",
    "        self.climate_monthly = pd.read_csv(\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/Climate/Monthly/GLC24-PA-train-bioclimatic_monthly.csv\")\n",
    "        self.climate = pd.merge(self.climate_average, self.climate_monthly, on=self.merge_key)\n",
    "        self.climate.fillna(self.climate.mean(),inplace=True)\n",
    "        self.climate_data = self.Norm_all(self.climate)\n",
    "\n",
    "        self.landsat_b = pd.read_csv(\"data/geolifeclef-2024/PA-train-landsat_time_series/GLC24-PA-train-landsat_time_series-blue.csv\")\n",
    "        self.landsat_b.fillna(self.landsat_b.mean(),inplace=True)\n",
    "        self.landsat_g = pd.read_csv(\"data/geolifeclef-2024/PA-train-landsat_time_series/GLC24-PA-train-landsat_time_series-green.csv\")\n",
    "        self.landsat_g.fillna(self.landsat_g.mean(),inplace=True)\n",
    "        self.landsat_r = pd.read_csv(\"data/geolifeclef-2024/PA-train-landsat_time_series/GLC24-PA-train-landsat_time_series-red.csv\")\n",
    "        self.landsat_r.fillna(self.landsat_r.mean(),inplace=True)\n",
    "        self.landsat_n = pd.read_csv(\"data/geolifeclef-2024/PA-train-landsat_time_series/GLC24-PA-train-landsat_time_series-nir.csv\")\n",
    "        self.landsat_n.fillna(self.landsat_n.mean(),inplace=True)\n",
    "        self.landsat_s1 = pd.read_csv(\"data/geolifeclef-2024/PA-train-landsat_time_series/GLC24-PA-train-landsat_time_series-swir1.csv\")\n",
    "        self.landsat_s1.fillna(self.landsat_s1.mean(),inplace=True)\n",
    "        self.landsat_s2 = pd.read_csv(\"data/geolifeclef-2024/PA-train-landsat_time_series/GLC24-PA-train-landsat_time_series-swir2.csv\")\n",
    "        self.landsat_s2.fillna(self.landsat_s2.mean(),inplace=True)\n",
    "        self.landsat_data = torch.cat([self.Norm_all(self.landsat_b),self.Norm_all(self.landsat_g),self.Norm_all(self.landsat_r),self.Norm_all(self.landsat_n),self.Norm_all(self.landsat_s1),self.Norm_all(self.landsat_s2)],axis=1)\n",
    "\n",
    "        self.elevation = pd.read_csv(\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/Elevation/GLC24-PA-train-elevation.csv\")\n",
    "        self.elevation[self.elevation<0]=0\n",
    "        self.elevation.fillna(self.elevation.mean(),inplace=True)\n",
    "        self.elevation_data = self.Norm(self.elevation)\n",
    "\n",
    "        self.human_footprint = pd.read_csv(\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/Human Footprint/GLC24-PA-train-human_footprint.csv\")\n",
    "        self.human_footprint[self.human_footprint<0]=0\n",
    "        self.human_footprint.fillna(self.human_footprint.mean(),inplace=True)\n",
    "        self.human_footprint_data = self.Norm(self.human_footprint)\n",
    "\n",
    "        self.landcover = pd.read_csv(\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/LandCover/GLC24-PA-train-landcover.csv\")\n",
    "        self.landcover[self.landcover<0]=0\n",
    "        self.landcover.fillna(self.landcover.mean(),inplace=True)\n",
    "        self.landcover_data = self.Norm(self.landcover)\n",
    "\n",
    "        self.soilgrids = pd.read_csv(\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/SoilGrids/GLC24-PA-train-soilgrids.csv\")\n",
    "        self.soilgrids[self.soilgrids<0]=0\n",
    "        self.soilgrids.fillna(self.soilgrids.mean(),inplace=True)\n",
    "        self.soilgrids_data = self.Norm(self.soilgrids)\n",
    "\n",
    "        self.metadata_data = torch.cat((self.metadata_data, self.elevation_data, self.human_footprint_data, self.landcover_data, self.soilgrids_data), dim=1)\n",
    "\n",
    "    def Norm(self,df):\n",
    "        output=torch.from_numpy(df.iloc[:,1:].values).float()\n",
    "        return (output-output.mean(dim=0))/output.std(dim=0)\n",
    "\n",
    "    def Norm_all(self,df):\n",
    "        output=torch.from_numpy(df.iloc[:,1:].values).float()\n",
    "        return (output-output.mean())/output.std()\n",
    "\n",
    "    def patch_rgb_path(self,survey_id):\n",
    "        path = \"data/geolifeclef-2024/PA_Train_SatellitePatches_RGB/pa_train_patches_rgb\"\n",
    "        for d in (str(survey_id)[-2:], str(survey_id)[-4:-2]):\n",
    "            path = os.path.join(path, d)\n",
    "        path = os.path.join(path, f\"{survey_id}.jpeg\")\n",
    "        return path\n",
    "\n",
    "    def patch_nir_path(self,survey_id):\n",
    "        path = \"data/geolifeclef-2024/PA_Train_SatellitePatches_NIR/pa_train_patches_nir\"\n",
    "        for d in (str(survey_id)[-2:], str(survey_id)[-4:-2]):\n",
    "            path = os.path.join(path, d)\n",
    "        path = os.path.join(path, f\"{survey_id}.jpeg\")\n",
    "        return path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        survey_id = self.metadata.surveyId[idx]\n",
    "\n",
    "        image_path = self.patch_rgb_path(survey_id)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        image = image.unsqueeze(0)\n",
    "        image_nir_path = self.patch_nir_path(survey_id)\n",
    "        nir_image = Image.open(image_nir_path).convert(\"L\")\n",
    "        nir_image = self.transform(nir_image)\n",
    "        nir_image = nir_image.unsqueeze(0)\n",
    "        image_data = torch.cat([image,nir_image],dim=1)\n",
    "        image_data = torch.squeeze(image_data)\n",
    "        sample=[self.metadata_data[idx,:],image_data,self.landsat_data[idx,:],self.climate_data[idx,:]]\n",
    "        species_ids = self.label_dict[survey_id]  # Get list of species IDs for the survey ID\n",
    "        label = torch.zeros(num_classes)  # Initialize label tensor\n",
    "        for species_id in species_ids:\n",
    "            label[species_id] = 1  # Set the corresponding class index to 1 for each species ID\n",
    "        count = len(species_ids)\n",
    "        return sample, survey_id, label, count#, species_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "af853980",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T21:25:32.627928Z",
     "start_time": "2024-04-30T21:25:32.612131Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-05T14:42:49.350022Z",
     "iopub.status.busy": "2024-05-05T14:42:49.349757Z",
     "iopub.status.idle": "2024-05-05T14:42:49.375102Z",
     "shell.execute_reply": "2024-05-05T14:42:49.374208Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.035054,
     "end_time": "2024-05-05T14:42:49.377072",
     "exception": false,
     "start_time": "2024-05-05T14:42:49.342018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, metadata, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "        self.metadata = metadata\n",
    "\n",
    "        self.metadata = self.metadata.drop_duplicates(subset=\"surveyId\").reset_index(drop=True)\n",
    "        self.metadata.fillna(0,inplace=True)\n",
    "        self.metadata.replace({float('-inf'): 0}, inplace=True)\n",
    "        self.metadata_data = self.Norm(self.metadata.iloc[:,:5])\n",
    "\n",
    "        self.merge_key = 'surveyId'\n",
    "        self.climate_average = pd.read_csv(\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/Climate/Average 1981-2010/GLC24-PA-test-bioclimatic.csv\")\n",
    "        self.climate_monthly = pd.read_csv(\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/Climate/Monthly/GLC24-PA-test-bioclimatic_monthly.csv\")\n",
    "        self.climate = pd.merge(self.climate_average, self.climate_monthly, on=self.merge_key)\n",
    "        self.climate.fillna(self.climate.mean(),inplace=True)\n",
    "        self.climate_data = self.Norm_all(self.climate)\n",
    "\n",
    "        self.landsat_b = pd.read_csv(\"data/geolifeclef-2024/PA-test-landsat_time_series/GLC24-PA-test-landsat_time_series-blue.csv\")\n",
    "        self.landsat_b.fillna(self.landsat_b.mean(),inplace=True)\n",
    "        self.landsat_g = pd.read_csv(\"data/geolifeclef-2024/PA-test-landsat_time_series/GLC24-PA-test-landsat_time_series-green.csv\")\n",
    "        self.landsat_g.fillna(self.landsat_g.mean(),inplace=True)\n",
    "        self.landsat_r = pd.read_csv(\"data/geolifeclef-2024/PA-test-landsat_time_series/GLC24-PA-test-landsat_time_series-red.csv\")\n",
    "        self.landsat_r.fillna(self.landsat_r.mean(),inplace=True)\n",
    "        self.landsat_n = pd.read_csv(\"data/geolifeclef-2024/PA-test-landsat_time_series/GLC24-PA-test-landsat_time_series-nir.csv\")\n",
    "        self.landsat_n.fillna(self.landsat_n.mean(),inplace=True)\n",
    "        self.landsat_s1 = pd.read_csv(\"data/geolifeclef-2024/PA-test-landsat_time_series/GLC24-PA-test-landsat_time_series-swir1.csv\")\n",
    "        self.landsat_s1.fillna(self.landsat_s1.mean(),inplace=True)\n",
    "        self.landsat_s2 = pd.read_csv(\"data/geolifeclef-2024/PA-test-landsat_time_series/GLC24-PA-test-landsat_time_series-swir2.csv\")\n",
    "        self.landsat_s2.fillna(self.landsat_s2.mean(),inplace=True)\n",
    "        self.landsat_data = torch.cat([self.Norm_all(self.landsat_b),self.Norm_all(self.landsat_g),self.Norm_all(self.landsat_r),self.Norm_all(self.landsat_n),self.Norm_all(self.landsat_s1),self.Norm_all(self.landsat_s2)],axis=1)\n",
    "\n",
    "        self.elevation = pd.read_csv(\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/Elevation/GLC24-PA-test-elevation.csv\")\n",
    "        self.elevation[self.elevation<0]=0\n",
    "        self.elevation.fillna(self.elevation.mean(),inplace=True)\n",
    "        self.elevation_data = self.Norm(self.elevation)\n",
    "\n",
    "        self.human_footprint = pd.read_csv(\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/Human Footprint/GLC24-PA-test-human_footprint.csv\")\n",
    "        self.human_footprint[self.human_footprint<0]=0\n",
    "        self.human_footprint.fillna(self.human_footprint.mean(),inplace=True)\n",
    "        self.human_footprint_data = self.Norm(self.human_footprint)\n",
    "\n",
    "        self.landcover = pd.read_csv(\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/LandCover/GLC24-PA-test-landcover.csv\")\n",
    "        self.landcover[self.landcover<0]=0\n",
    "        self.landcover.fillna(self.landcover.mean(),inplace=True)\n",
    "        self.landcover_data = self.Norm(self.landcover)\n",
    "\n",
    "        self.soilgrids = pd.read_csv(\"data/geolifeclef-2024/EnvironmentalRasters/EnvironmentalRasters/SoilGrids/GLC24-PA-test-soilgrids.csv\")\n",
    "        self.soilgrids[self.soilgrids<0]=0\n",
    "        self.soilgrids.fillna(self.soilgrids.mean(),inplace=True)\n",
    "        self.soilgrids_data = self.Norm(self.soilgrids)\n",
    "\n",
    "        self.metadata_data = torch.cat((self.metadata_data, self.elevation_data, self.human_footprint_data, self.landcover_data, self.soilgrids_data), dim=1)\n",
    "\n",
    "    def Norm(self,df):\n",
    "        output=torch.from_numpy(df.iloc[:,1:].values).float()\n",
    "        return (output-output.mean(dim=0))/output.std(dim=0)\n",
    "\n",
    "    def Norm_all(self,df):\n",
    "        output=torch.from_numpy(df.iloc[:,1:].values).float()\n",
    "        return (output-output.mean())/output.std()\n",
    "\n",
    "    def patch_rgb_path(self,survey_id):\n",
    "        path = \"data/geolifeclef-2024/PA_Test_SatellitePatches_RGB/pa_test_patches_rgb\"\n",
    "        for d in (str(survey_id)[-2:], str(survey_id)[-4:-2]):\n",
    "            path = os.path.join(path, d)\n",
    "        path = os.path.join(path, f\"{survey_id}.jpeg\")\n",
    "        return path\n",
    "\n",
    "    def patch_nir_path(self,survey_id):\n",
    "        path = \"data/geolifeclef-2024/PA_Test_SatellitePatches_NIR/pa_test_patches_nir\"\n",
    "        for d in (str(survey_id)[-2:], str(survey_id)[-4:-2]):\n",
    "            path = os.path.join(path, d)\n",
    "        path = os.path.join(path, f\"{survey_id}.jpeg\")\n",
    "        return path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        survey_id = self.metadata.surveyId[idx]\n",
    "\n",
    "        image_path = self.patch_rgb_path(survey_id)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        image = image.unsqueeze(0)\n",
    "        image_nir_path = self.patch_nir_path(survey_id)\n",
    "        nir_image = Image.open(image_nir_path).convert(\"L\")\n",
    "        nir_image = self.transform(nir_image)\n",
    "        nir_image = nir_image.unsqueeze(0)\n",
    "        image_data = torch.cat([image,nir_image],dim=1)\n",
    "        image_data = torch.squeeze(image_data)\n",
    "        sample=[self.metadata_data[idx,:],image_data,self.landsat_data[idx,:],self.climate_data[idx,:]]\n",
    "        return sample, survey_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "39b64182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T21:25:34.532017Z",
     "start_time": "2024-04-30T21:25:32.615562Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-05T14:42:49.391704Z",
     "iopub.status.busy": "2024-05-05T14:42:49.391421Z",
     "iopub.status.idle": "2024-05-05T14:42:51.305244Z",
     "shell.execute_reply": "2024-05-05T14:42:51.304427Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.923732,
     "end_time": "2024-05-05T14:42:51.307566",
     "exception": false,
     "start_time": "2024-05-05T14:42:49.383834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset and DataLoader\n",
    "train_batch_size = 64\n",
    "test_batch_size = 1\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load training data\n",
    "train_metadata_path = \"data/geolifeclef-2024/GLC24_PA_metadata_train.csv\"\n",
    "train_metadata = pd.read_csv(train_metadata_path)\n",
    "train_dataset = TrainDataset(train_metadata, subset=\"train\", transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "# Load testing data\n",
    "test_metadata_path = \"data/geolifeclef-2024/GLC24_PA_metadata_test.csv\"\n",
    "test_metadata = pd.read_csv(test_metadata_path)\n",
    "test_dataset = TestDataset(test_metadata, subset=\"test\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b334f1d",
   "metadata": {
    "papermill": {
     "duration": 0.006256,
     "end_time": "2024-05-05T14:42:51.490923",
     "exception": false,
     "start_time": "2024-05-05T14:42:51.484667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is the **final multi-modal model**. Unlike ViT, its input is features extracted from each dimension. \n",
    "\n",
    "For features with time information, I added additional position information. \n",
    "\n",
    "At the same time, I also added a feature that is a fusion of the first four features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0f8dde92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T14:42:51.505245Z",
     "iopub.status.busy": "2024-05-05T14:42:51.504543Z",
     "iopub.status.idle": "2024-05-05T14:42:51.515887Z",
     "shell.execute_reply": "2024-05-05T14:42:51.515235Z"
    },
    "papermill": {
     "duration": 0.020283,
     "end_time": "2024-05-05T14:42:51.517661",
     "exception": false,
     "start_time": "2024-05-05T14:42:51.497378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiModal(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultiModal, self).__init__()\n",
    "        self.cls = nn.Parameter(torch.randn(1, 1, 200))\n",
    "        self.meta = MLP(31,200)\n",
    "        self.resnet18 = ResNet18(200)\n",
    "        self.landsat = MLP(504,200)\n",
    "        self.position_landsat = nn.Parameter(torch.randn(1, 504))\n",
    "        self.climate = MLP(931,200)\n",
    "        self.position_climate = nn.Parameter(torch.randn(1, 931))\n",
    "        self.emb = MLP(800,200)\n",
    "        self.position_combine = nn.Parameter(torch.randn(1, 800))\n",
    "        self.vit = ViT(200, 2, 200, 400, num_classes)\n",
    "        self.position = nn.Parameter(torch.randn(1, 6, 200))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch = x[0].size(0)\n",
    "        CLS = repeat(self.cls, '1 1 d -> b 1 d', b=batch).to(device)\n",
    "        META = self.meta(x[0])\n",
    "        IMG = self.resnet18(x[1])\n",
    "        LANDSAT = self.landsat(x[2]+self.position_landsat)\n",
    "        CLIMATE = self.climate(x[3]+self.position_climate)\n",
    "        combine = torch.cat((META, IMG, LANDSAT, CLIMATE), dim=1)\n",
    "        COMBINE = self.emb(combine+self.position_combine)\n",
    "        token = torch.concat((CLS, META.unsqueeze(1)), dim=1)\n",
    "        token = torch.concat((token, IMG.unsqueeze(1)), dim=1)\n",
    "        token = torch.concat((token, LANDSAT.unsqueeze(1)), dim=1)\n",
    "        token = torch.concat((token, CLIMATE.unsqueeze(1)), dim=1)\n",
    "        token = torch.concat((token, COMBINE.unsqueeze(1)), dim=1)\n",
    "        out = self.vit(token+self.position)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8e1f40e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T21:25:31.611823Z",
     "start_time": "2024-04-30T21:25:31.607373Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-05T14:42:51.531532Z",
     "iopub.status.busy": "2024-05-05T14:42:51.531262Z",
     "iopub.status.idle": "2024-05-05T14:42:52.798635Z",
     "shell.execute_reply": "2024-05-05T14:42:52.797682Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.276491,
     "end_time": "2024-05-05T14:42:52.800566",
     "exception": false,
     "start_time": "2024-05-05T14:42:51.524075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE = CUDA\n"
     ]
    }
   ],
   "source": [
    "# Check if cuda is available\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"DEVICE = CUDA\")\n",
    "\n",
    "model = MultiModal(num_classes).to(device)\n",
    "# model.load_state_dict(torch.load(\"models/vit/Model.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ba363e",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c7e9665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/startung/miniconda3/envs/pt/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00025)\n",
    "# logger.info(\"Optimizer: AdamW\")\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, verbose=True)\n",
    "# logger.info(\"Scheduler: CosineAnnealingLR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0dc6840b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10 epochs started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 0/1391, Loss: 0.7349907755851746\n",
      "Epoch 1/10, Batch 139/1391, Loss: 0.02957274578511715\n",
      "Epoch 1/10, Batch 278/1391, Loss: 0.014072997495532036\n",
      "Epoch 1/10, Batch 417/1391, Loss: 0.010164381004869938\n",
      "Epoch 1/10, Batch 556/1391, Loss: 0.008698096498847008\n",
      "Epoch 1/10, Batch 695/1391, Loss: 0.00786302238702774\n",
      "Epoch 1/10, Batch 834/1391, Loss: 0.008332272991538048\n",
      "Epoch 1/10, Batch 973/1391, Loss: 0.007484139874577522\n",
      "Epoch 1/10, Batch 1112/1391, Loss: 0.006611760705709457\n",
      "Epoch 1/10, Batch 1251/1391, Loss: 0.0067728441208601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [04:22<39:18, 262.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 1390/1391, Loss: 0.0052049607038497925\n",
      "Epoch 2/10, Batch 0/1391, Loss: 0.005556697025895119\n",
      "Epoch 2/10, Batch 139/1391, Loss: 0.005286019295454025\n",
      "Epoch 2/10, Batch 278/1391, Loss: 0.005960514303296804\n",
      "Epoch 2/10, Batch 417/1391, Loss: 0.005892543122172356\n",
      "Epoch 2/10, Batch 556/1391, Loss: 0.005626040045171976\n",
      "Epoch 2/10, Batch 695/1391, Loss: 0.005467662587761879\n",
      "Epoch 2/10, Batch 834/1391, Loss: 0.006014578510075808\n",
      "Epoch 2/10, Batch 973/1391, Loss: 0.0055175600573420525\n",
      "Epoch 2/10, Batch 1112/1391, Loss: 0.004954695701599121\n",
      "Epoch 2/10, Batch 1251/1391, Loss: 0.005378980189561844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [08:43<34:55, 261.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Batch 1390/1391, Loss: 0.004102400969713926\n",
      "Epoch 3/10, Batch 0/1391, Loss: 0.0044676270335912704\n",
      "Epoch 3/10, Batch 139/1391, Loss: 0.00430769007652998\n",
      "Epoch 3/10, Batch 278/1391, Loss: 0.004963258281350136\n",
      "Epoch 3/10, Batch 417/1391, Loss: 0.005102289840579033\n",
      "Epoch 3/10, Batch 556/1391, Loss: 0.004979284945875406\n",
      "Epoch 3/10, Batch 695/1391, Loss: 0.004836549982428551\n",
      "Epoch 3/10, Batch 834/1391, Loss: 0.0052825817838311195\n",
      "Epoch 3/10, Batch 973/1391, Loss: 0.004920740611851215\n",
      "Epoch 3/10, Batch 1112/1391, Loss: 0.004498898051679134\n",
      "Epoch 3/10, Batch 1251/1391, Loss: 0.00496812304481864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [13:05<30:33, 261.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Batch 1390/1391, Loss: 0.0037807265762239695\n",
      "Epoch 4/10, Batch 0/1391, Loss: 0.00413262564688921\n",
      "Epoch 4/10, Batch 139/1391, Loss: 0.00396841811016202\n",
      "Epoch 4/10, Batch 278/1391, Loss: 0.004581856541335583\n",
      "Epoch 4/10, Batch 417/1391, Loss: 0.0047548385336995125\n",
      "Epoch 4/10, Batch 556/1391, Loss: 0.004730638116598129\n",
      "Epoch 4/10, Batch 695/1391, Loss: 0.004518009722232819\n",
      "Epoch 4/10, Batch 834/1391, Loss: 0.004996577277779579\n",
      "Epoch 4/10, Batch 973/1391, Loss: 0.004587549716234207\n",
      "Epoch 4/10, Batch 1112/1391, Loss: 0.004273323342204094\n",
      "Epoch 4/10, Batch 1251/1391, Loss: 0.0047425776720047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [17:28<26:13, 262.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Batch 1390/1391, Loss: 0.0035886599216610193\n",
      "Epoch 5/10, Batch 0/1391, Loss: 0.0039310818538069725\n",
      "Epoch 5/10, Batch 139/1391, Loss: 0.003820506390184164\n",
      "Epoch 5/10, Batch 278/1391, Loss: 0.004376373253762722\n",
      "Epoch 5/10, Batch 417/1391, Loss: 0.0045401244424283504\n",
      "Epoch 5/10, Batch 556/1391, Loss: 0.004584381356835365\n",
      "Epoch 5/10, Batch 695/1391, Loss: 0.004343959502875805\n",
      "Epoch 5/10, Batch 834/1391, Loss: 0.004824021831154823\n",
      "Epoch 5/10, Batch 973/1391, Loss: 0.004419183358550072\n",
      "Epoch 5/10, Batch 1112/1391, Loss: 0.004129873588681221\n",
      "Epoch 5/10, Batch 1251/1391, Loss: 0.004615657962858677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [21:50<21:51, 262.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Batch 1390/1391, Loss: 0.003461048472672701\n",
      "Epoch 6/10, Batch 0/1391, Loss: 0.0037960680201649666\n",
      "Epoch 6/10, Batch 139/1391, Loss: 0.0037056072615087032\n",
      "Epoch 6/10, Batch 278/1391, Loss: 0.004274362698197365\n",
      "Epoch 6/10, Batch 417/1391, Loss: 0.004382345825433731\n",
      "Epoch 6/10, Batch 556/1391, Loss: 0.004442816600203514\n",
      "Epoch 6/10, Batch 695/1391, Loss: 0.004224259406328201\n",
      "Epoch 6/10, Batch 834/1391, Loss: 0.004653670359402895\n",
      "Epoch 6/10, Batch 973/1391, Loss: 0.00428025983273983\n",
      "Epoch 6/10, Batch 1112/1391, Loss: 0.004079033620655537\n",
      "Epoch 6/10, Batch 1251/1391, Loss: 0.004521721974015236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [26:12<17:28, 262.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Batch 1390/1391, Loss: 0.0034094664733856916\n",
      "Epoch 7/10, Batch 0/1391, Loss: 0.00365727161988616\n",
      "Epoch 7/10, Batch 139/1391, Loss: 0.0036135478876531124\n",
      "Epoch 7/10, Batch 278/1391, Loss: 0.004168370272964239\n",
      "Epoch 7/10, Batch 417/1391, Loss: 0.004273276310414076\n",
      "Epoch 7/10, Batch 556/1391, Loss: 0.004323720466345549\n",
      "Epoch 7/10, Batch 695/1391, Loss: 0.004133121110498905\n",
      "Epoch 7/10, Batch 834/1391, Loss: 0.004563512280583382\n",
      "Epoch 7/10, Batch 973/1391, Loss: 0.004167885985225439\n",
      "Epoch 7/10, Batch 1112/1391, Loss: 0.00400905217975378\n",
      "Epoch 7/10, Batch 1251/1391, Loss: 0.004478261806070805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [30:34<13:06, 262.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Batch 1390/1391, Loss: 0.0033434201031923294\n",
      "Epoch 8/10, Batch 0/1391, Loss: 0.003550377208739519\n",
      "Epoch 8/10, Batch 139/1391, Loss: 0.0035694686230272055\n",
      "Epoch 8/10, Batch 278/1391, Loss: 0.004242718685418367\n",
      "Epoch 8/10, Batch 417/1391, Loss: 0.004150160122662783\n",
      "Epoch 8/10, Batch 556/1391, Loss: 0.004205682780593634\n",
      "Epoch 8/10, Batch 695/1391, Loss: 0.004084913060069084\n",
      "Epoch 8/10, Batch 834/1391, Loss: 0.004431955050677061\n",
      "Epoch 8/10, Batch 973/1391, Loss: 0.004082387313246727\n",
      "Epoch 8/10, Batch 1112/1391, Loss: 0.003938659094274044\n",
      "Epoch 8/10, Batch 1251/1391, Loss: 0.0043869661167263985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [34:57<08:44, 262.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Batch 1390/1391, Loss: 0.00326737598516047\n",
      "Epoch 9/10, Batch 0/1391, Loss: 0.003517943900078535\n",
      "Epoch 9/10, Batch 139/1391, Loss: 0.003511570394039154\n",
      "Epoch 9/10, Batch 278/1391, Loss: 0.003980784676969051\n",
      "Epoch 9/10, Batch 417/1391, Loss: 0.004085118882358074\n",
      "Epoch 9/10, Batch 556/1391, Loss: 0.004177015274763107\n",
      "Epoch 9/10, Batch 695/1391, Loss: 0.004043424502015114\n",
      "Epoch 9/10, Batch 834/1391, Loss: 0.004429874941706657\n",
      "Epoch 9/10, Batch 973/1391, Loss: 0.003990948665887117\n",
      "Epoch 9/10, Batch 1112/1391, Loss: 0.00386800873093307\n",
      "Epoch 9/10, Batch 1251/1391, Loss: 0.0043358877301216125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [39:19<04:22, 262.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Batch 1390/1391, Loss: 0.0031601854134351015\n",
      "Epoch 10/10, Batch 0/1391, Loss: 0.003447657683864236\n",
      "Epoch 10/10, Batch 139/1391, Loss: 0.0034442697651684284\n",
      "Epoch 10/10, Batch 278/1391, Loss: 0.003933025524020195\n",
      "Epoch 10/10, Batch 417/1391, Loss: 0.004025811795145273\n",
      "Epoch 10/10, Batch 556/1391, Loss: 0.0040794555097818375\n",
      "Epoch 10/10, Batch 695/1391, Loss: 0.003927966579794884\n",
      "Epoch 10/10, Batch 834/1391, Loss: 0.0043701184913516045\n",
      "Epoch 10/10, Batch 973/1391, Loss: 0.003941917326301336\n",
      "Epoch 10/10, Batch 1112/1391, Loss: 0.003791925497353077\n",
      "Epoch 10/10, Batch 1251/1391, Loss: 0.004210730083286762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [43:41<00:00, 262.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Batch 1390/1391, Loss: 0.0031075396109372377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training for {num_epochs} epochs started.\")\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (sample, survey_id, labels, count) in enumerate(train_loader):\n",
    "        samples = [tensor.to(device) for tensor in sample]\n",
    "        survey_id = survey_id.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # with torch.set_grad_enabled(True):\n",
    "        outputs = model(samples)\n",
    "\n",
    "        # pos_weight = labels*1.0  # All positive weights are equal to 10\n",
    "        # criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        criterion = torch.nn.MultiLabelSoftMarginLoss()\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % (len(train_loader)//10) == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item()}\")\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(model.state_dict(), new_dir / f\"multimodal-epoch-{epoch}.pth\")\n",
    "\n",
    "    scheduler.step()\n",
    "torch.save(model.state_dict(), new_dir / \"multimodal-final.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fa615b",
   "metadata": {},
   "source": [
    "## Produce Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5ad6677f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-30T21:25:34.536634Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-05T14:42:52.815910Z",
     "iopub.status.busy": "2024-05-05T14:42:52.815177Z",
     "iopub.status.idle": "2024-05-05T14:44:06.291126Z",
     "shell.execute_reply": "2024-05-05T14:44:06.288992Z"
    },
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 73.485486,
     "end_time": "2024-05-05T14:44:06.293057",
     "exception": false,
     "start_time": "2024-05-05T14:42:52.807571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4716/4716 [00:11<00:00, 424.03it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    surveys = []\n",
    "    top_indices = []\n",
    "    for data, surveyID in tqdm(test_loader, total=len(test_loader)):\n",
    "\n",
    "        data = [tensor.to(device) for tensor in data]\n",
    "\n",
    "        outputs = model(data)\n",
    "        predictions = torch.sigmoid(outputs).cpu().numpy()\n",
    "        predictions = np.squeeze(predictions)\n",
    "        # print(predictions)\n",
    "        prediction = np.argwhere(predictions>=0.25).flatten()\n",
    "        top_indices.append(prediction)\n",
    "        surveys.extend(surveyID.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6632f95d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T14:44:06.404548Z",
     "iopub.status.busy": "2024-05-05T14:44:06.404201Z",
     "iopub.status.idle": "2024-05-05T14:44:06.506275Z",
     "shell.execute_reply": "2024-05-05T14:44:06.505581Z"
    },
    "papermill": {
     "duration": 0.159619,
     "end_time": "2024-05-05T14:44:06.508072",
     "exception": false,
     "start_time": "2024-05-05T14:44:06.348453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_concatenated = [' '.join(map(str, row)) for row in top_indices]\n",
    "\n",
    "pd.DataFrame(\n",
    "    {'surveyId': surveys,\n",
    "     'predictions': data_concatenated,\n",
    "    }).to_csv(new_dir / \"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3f553810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of predictions: 77425 with average of 16.41751484308736 predictions per survey ID.\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for row in top_indices:\n",
    "    total += row.shape[0]\n",
    "\n",
    "print(f\"Total number of predictions: {total} with average of {total/len(top_indices)} predictions per survey ID.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8171035,
     "sourceId": 64733,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 36765,
     "sourceId": 43782,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 102.728954,
   "end_time": "2024-05-05T14:44:08.185017",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-05T14:42:25.456063",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
